{
  "title": "Persona-aware Generative Model for Code-mixed Language",
  "authors": [
    "Ayan Sengupta",
    "Md Shad Akhtar",
    "Tanmoy Chakraborty"
  ],
  "submission_date": "2023-09-06T11:20:41+00:00",
  "revised_dates": [
    "2024-10-19T07:06:30+00:00"
  ],
  "publication_venue": null,
  "abstract": "Code-mixing and script-mixing are prevalent across online social networks and\nmultilingual societies. However, a user's preference toward code-mixing depends\non the socioeconomic status, demographics of the user, and the local context,\nwhich existing generative models mostly ignore while generating code-mixed\ntexts. In this work, we make a pioneering attempt to develop a persona-aware\ngenerative model to generate texts resembling real-life code-mixed texts of\nindividuals. We propose a Persona-aware Generative Model for Code-mixed\nGeneration, PARADOX, a novel Transformer-based encoder-decoder model that\nencodes an utterance conditioned on a user's persona and generates code-mixed\ntexts without monolingual reference data. We propose an alignment module that\nre-calibrates the generated sequence to resemble real-life code-mixed texts.\nPARADOX generates code-mixed texts that are semantically more meaningful and\nlinguistically more valid. To evaluate the personification capabilities of\nPARADOX, we propose four new metrics -- CM BLEU, CM Rouge-1, CM Rouge-L and CM\nKS. On average, PARADOX achieves 1.6 points better CM BLEU, 47% better\nperplexity and 32% better semantic coherence than the non-persona-based\ncounterparts.",
  "categories": [
    "cs.CL",
    "cs.LG"
  ],
  "arxiv_id": "2309.02915"
}