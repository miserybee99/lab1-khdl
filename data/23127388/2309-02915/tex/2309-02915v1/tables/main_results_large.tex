\begin{table*}[!t]
\centering
\scalebox{0.85}{
{\begin{tabular}{lrrrrrrrr}
\toprule
\textbf{Model} &\multicolumn{2}{c}{\textbf{CM BLEU} $\uparrow$} &\multicolumn{2}{c}{\textbf{CM Rouge-1} $\uparrow$} &\multicolumn{2}{c}{\textbf{CM Rouge-L} $\uparrow$} &\multicolumn{2}{c}{\textbf{CM KS} $\downarrow$} \\\cmidrule{2-9}
\textbf{} &\textbf{Twitter} &\textbf{YouTube} &\textbf{Twitter} &\textbf{YouTube} &\textbf{Twitter} &\textbf{YouTube} &\textbf{Twitter} & \textbf{YouTube} \\\midrule
MuRIL & 9.92 & 9.85 & 26.93 & 21.10 & 23.65 & 19.63 & 0.42 & \textbf{0.23}\\
BLOOMZ & 14.20 & 23.87 & 49.22 & 56.61 & 45.93 & 55.09 & 0.40 & 0.30 \\
Llama 2 (zero-shot) & 19.97 & 7.25 & 48.91 & 30.86 & 43.74 & 28.72 & 0.56 & 0.43\\
Llama 2 (1-shot) & 26.69 & 20.03 & 55.17 & 46.08 & 49.57 & 43.17 & 0.50 & 0.39\\
\color{black} Llama 2 (fine-tuned) &  \color{black}  21.97 & \color{black}  26.09 & \color{black} 55.89 & \color{black} 58.24 & \color{black} 51.07 & \color{black} 55.17 & \color{black} 0.40 & \color{black} \textbf{0.34} \\
\color{black} GPT-4 (zero-shot) & \color{black} \color{black} 30.94 & \color{black} 30.33 & \color{black} 57.46 & \color{black} 57.88 & \color{black} 50.89 & \color{black} 53.69 & \color{black} 0.42 & \color{black} 0.39 \\
\color{black} GPT-4 (1-shot) & \color{black} \color{black} \textbf{31.90} & \color{black} 30.57 & \color{black} 60.67 & \color{black} 61.46 & \color{black} \textbf{54.55} & \color{black} 57.34 & \color{black} 0.42 & \color{black} 0.36 \\
\hline
\color{black} Transformer & 22.21 & 29.36 & 58.69 & 61.02 & 51.10 & 57.27 & 0.42 & 0.37 \\
%\hdashline
%(+) Distillation & 22.52 & 29.68 & 59.35 & 61.30 & 51.91 & 57.45 & 0.38 & 0.39 \\
%(+) Meta Distillation & 20.94 & 30.62 & 56.40 & 61.73 & 49.79 & 58.14 & 0.37 & 0.42\\
\hline
\rowcolor{maroon!10}  {\modelname} & 24.58 & \bf 31.37 & 60.60 & \bf 62.90 & 53.03 & \bf 59.16 &  0.36 & \bf 0.34  \\
%\hdashline
%\rowcolor{maroon!10}  (+) Distillation & 21.63 & 30.64 & 58.54 & 62.10 & 51.26 & 58.44& 0.34 & 0.41\\
%\rowcolor{maroon!10}  (+) Meta Distillation & 24.38 & 30.04 & \textbf{60.79} & 61.90 & \textbf{53.18} & 58.52 & 0.32 & 0.48\\
\hdashline
\rowcolor{maroon!10}  (-) Contextual Persona & 24.06 & 30.67 & 60.03 & 62.44 & 52.52 & 58.71 & 0.35 & \bf 0.34  \\
\rowcolor{maroon!10}  (-) Speaker ID & 20.10 & 31.01 & 56.46 & 62.72 & 49.71 & 58.96 & 0.35 & \bf 0.34\\
\rowcolor{maroon!10}  (-) Alignment & 24.37 & 31.08 & \bf 60.79 & 62.46 & 53.18 & 59.15 &  \bf 0.32 & 0.37\\
\rowcolor{maroon!10}  (-) FAME & 18.49 & 28.29 & 54.01 & 60.67 & 47.68 & 57.10 & 0.36 & 0.37 \\
\bottomrule
\end{tabular}
}}
\caption{Extrinsic evaluation of pre-trained language models, Transformer and {\modelname} in terms of preserving user-level switching patterns ($\uparrow$ ({\em resp.} $\downarrow$): higher ({\em resp.} lower) value indicates better performance). \color{black}\textbf{Bold} indicates the best results among all the models.}
\label{tab:main_result}
\vspace{-5mm}
\end{table*}