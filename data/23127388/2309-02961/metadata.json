{
  "title": "LuViRA Dataset Validation and Discussion: Comparing Vision, Radio, and Audio Sensors for Indoor Localization",
  "authors": [
    "Ilayda Yaman",
    "Guoda Tian",
    "Erik Tegler",
    "Jens Gulin",
    "Nikhil Challa",
    "Fredrik Tufvesson",
    "Ove Edfors",
    "Kalle Astrom",
    "Steffen Malkowsky",
    "Liang Liu"
  ],
  "submission_date": "2023-09-06T12:57:00+00:00",
  "revised_dates": [
    "2024-04-25T08:54:21+00:00"
  ],
  "publication_venue": "IEEE Journal of Indoor and Seamless Positioning and Navigation\n  (2024) 1-11",
  "abstract": "We present a unique comparative analysis, and evaluation of vision, radio,\nand audio based localization algorithms. We create the first baseline for the\naforementioned sensors using the recently published Lund University Vision,\nRadio, and Audio (LuViRA) dataset, where all the sensors are synchronized and\nmeasured in the same environment. Some of the challenges of using each specific\nsensor for indoor localization tasks are highlighted. Each sensor is paired\nwith a current state-of-the-art localization algorithm and evaluated for\ndifferent aspects: localization accuracy, reliability and sensitivity to\nenvironment changes, calibration requirements, and potential system complexity.\nSpecifically, the evaluation covers the ORB-SLAM3 algorithm for vision-based\nlocalization with an RGB-D camera, a machine-learning algorithm for radio-based\nlocalization with massive MIMO technology, and the SFS2 algorithm for\naudio-based localization with distributed microphones. The results can serve as\na guideline and basis for further development of robust and high-precision\nmulti-sensory localization systems, e.g., through sensor fusion, context, and\nenvironment-aware adaptation.",
  "categories": [
    "eess.SP",
    "cs.CV",
    "cs.SD",
    "eess.AS"
  ],
  "arxiv_id": "2309.02961"
}