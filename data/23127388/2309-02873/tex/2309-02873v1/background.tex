% !TEX root = main.tex

\section{Background: Observer Design} \label{section:background}
In this work, we leverage observers, a concept from control theory in order to infer the unknown latent states of a learning-based model via a black-box simulator. 
Here, we provide the necessary background on observer design \citep{8472168,cdc-2019}.
Consider a system 
\begin{equation}\label{eq:simple}
\begin{aligned}
u_{n+1}&=f_u(u_n) \\
\hat s &=h(u_n),
\end{aligned}
\end{equation}
with dynamics $f_u:\mathbb{R}^{d_u} \rightarrow \mathbb{R}^{d_u}$, observation model $h:\mathbb{R}^{d_u} \rightarrow \mathbb{R}^{d_s}$ and measurements $\hat s$.
The latent states $u$ are denoted \emph{observable} in case they can be inferred from measurements  $\hat s$ over time, regardless of the initial condition, given known dynamics $f_u$.
The algorithm fulfilling this task is denoted observer. 
In contrast to the standard ML terminology, observable states are \emph{latent} and cannot be measured.

Partially observable systems denote systems, where only parts of the states can be reconstructed from the outputs via an observer \eqref{eq:observer} \citep{TAMI201654, Robenack2006}.  
 
\paragraph{Observer: }
The goal of an observer is to reconstruct the unknown but observable latent states $u$ from outputs $\hat s$ and known dynamics. Here, we refer to an observer as a mapping $\mathcal T$ that produces an estimate
$\tilde{u}$ with $\tilde{u}_{n+1}=\mathcal{T}(\hat s_1,\dots,\hat s_n,\tilde{u}_0)$ and
\begin{equation}\label{eq:observer}
|u_n-\tilde{u}_n| \rightarrow 0, n \rightarrow \infty. 
\end{equation}


\subsection{KKL observer}\label{sec:KKL}
In this work, we consider the so-called Kazantzisâ€“Kravaris/Luenberger (KKL) observers due to their beneficial properties such as robustness against model mismatch \citep{DBLP:journals/corr/abs-2210-01476}. 
They can be designed in the continuous-time and discrete-time case \cite{8472168,cdc-2019}.
In the following, let $\mathcal U_0 \subset \mathcal U \subset  \mathbb{R}^{d_u}$  be a compact subset such that for
all initial conditions $u_0 \in \mathcal{U}_0$ and all $n \in \mathbb{N}$ it holds that $u_n \in \mathcal{U}$.
We will define the central properties of KKL observers here.
Mathematical details are added in Appendix Sec. 1.1. 
The key criterion for the existence of KKL observers is the so-called backward-distinguishability. 

\paragraph{Backward-distinguishability: }
Intuitively, for distinguishable trajectories in the latent space with $u_0^a \neq u_0^b$, there exists a point $t<0$ in the past, for which
the respective outputs are distinguishable as well, thus $\hat s_{t}^a \neq \hat s_{t}^b$.

\paragraph{Controllable pair: }
A matrix pair $(D,F)$ with $D \in \mathbb{R}^{d_u \times d_u}$ and $F \in \mathbb{R}^{d_u \times d_s}$ is denoted
controllable if the controllability matrix $C = [F, DF, D^2F,\dots,D^{d_u-1}F]$ has full row rank \citep{ogata1997modern}.

\paragraph{KKL observer: }
Define $d_z = d_y(d_u + 1)$.
Consider a backward-distinguishable system with dynamics $f_u$ and observation function $h$.
Furthermore, let $(D,F)$ be a controllable pair, where the eigenvalues $\lambda_1,\dots,\lambda_{d_z}$ of $D$ fulfill $\max(|\lambda_i|)<1$.
Then, under additional mild assumptions, there exists a continuous injective mapping
$T:\mathbb R^{d_u} \to \mathbb{R}^{d_z}$ with continuous pseudo-inverse
$T^{\star}:\mathbb R^{d_z} \to \mathbb{R}^{d_u}$ and
\begin{equation}\label{eq:KKL}
\begin{aligned}
T(f_u(u))=DT(u)+Fh(u)
\end{aligned}
\end{equation}
on $\mathcal U$ and 
\begin{equation} \label{eq:observation}
\lim_{n \rightarrow \infty} |u_n-T^{\star}(z_n)|=0
\end{equation}
for any trajectory defined via $z_{n+1}=Dz_n+F \hat s_n$.
Thus, $T^{\star}(z)$ is an observer for $u$.
 
\paragraph{Properties and limits: }
It is not clear how to obtain the transformation $T$ though its existence is guaranteed. 
\citet{9304163,9683485} approach the problem by sampling trajectories for $u$ and $z$ and solving regression problems for $T$. 
However, there is a significant difference since we consider the case of \emph{unknown} dynamics $f_u$.
Still, we benefit from the properties of KKL observers as we will demonstrate in the following sections.
We parametrize $T$ with a neural network (NN) similarly to \citet{9683277} that consider a learning-based but not a HM scenario. 