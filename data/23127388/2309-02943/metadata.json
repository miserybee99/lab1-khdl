{
  "title": "Drag-reduction strategies in wall-bounded turbulent flows using deep reinforcement learning",
  "authors": [
    "L. Guastoni",
    "J. Rabault",
    "H. Azizpour",
    "R. Vinuesa"
  ],
  "submission_date": "2023-09-06T12:21:14+00:00",
  "revised_dates": [
    "2023-09-06T12:21:14+00:00"
  ],
  "publication_venue": null,
  "abstract": "In this work we compare different drag-reduction strategies that compute\ntheir actuation based on the fluctuations at a given wall-normal location in\nturbulent open channel flow. In order to perform this study, we implement and\ndescribe in detail the reinforcement-learning interface to a\ncomputationally-efficient, parallelized, high-fidelity solver for fluid-flow\nsimulations. We consider opposition control (Choi, Moin, and Kim, Journal of\nFluid Mechanics 262, 1994) and the policies learnt using deep reinforcement\nlearning (DRL) based on the state of the flow at two inner-scaled locations\n($y^+ = 10$ and $y^+ = 15$). By using deep deterministic policy gradient (DDPG)\nalgorithm, we are able to discover control strategies that outperform existing\ncontrol methods. This represents a first step in the exploration of the\ncapability of DRL algorithm to discover effective drag-reduction policies using\ninformation from different locations in the flow.",
  "categories": [
    "physics.flu-dyn"
  ],
  "arxiv_id": "2309.02943"
}