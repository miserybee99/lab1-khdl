@article{Nousiainen:21,
author = {Jalo Nousiainen and Chang Rajani and Markus Kasper and Tapio Helin},
journal = {Optics Express},
keywords = {Astronomical optics; Deformable mirrors; Image quality; Numerical simulation; Optical control systems; Stochastic gradient descent},
number = {10},
pages = {15327--15344},
publisher = {Optica Publishing Group},
title = {Adaptive optics control using model-based reinforcement learning},
volume = {29},
month = {May},
year = {2021},
url = {http://opg.optica.org/oe/abstract.cfm?URI=oe-29-10-15327},
doi = {10.1364/OE.420270}}

@article{Beeler:19,
  title = {Optimizing thermodynamic trajectories using evolutionary and gradient-based reinforcement learning},
  author = {Beeler, Chris and Yahorau, Uladzimir and Coles, Rory and Mills, Kyle and Whitelam, Stephen and Tamblyn, Isaac},
  journal = {Phys. Rev. E},
  volume = {104},
  issue = {6},
  pages = {064128},
  numpages = {10},
  year = {2021},
  month = {Dec},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.104.064128},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.064128}
}

@article{tang2020robust,
  title={Robust active flow control over a range of {R}eynolds numbers using an artificial neural network trained through deep reinforcement learning},
  author={Tang, Hongwei and Rabault, Jean and Kuhnle, Alexander and Wang, Yan and Wang, Tongguang},
  journal={Physics of Fluids},
  volume={32},
  number={5},
  pages={053605},
  year={2020},
  publisher={AIP Publishing LLC}
}

@article{doi:10.1063/5.0052524,
author = {Zheng,Changdong and Ji,Tingwei and Xie,Fangfang and Zhang,Xinshuai and Zheng,Hongyu and Zheng,Yao},
title = {From active learning to deep reinforcement learning: Intelligent active flow control in suppressing vortex-induced vibration},
journal = {Physics of Fluids},
volume = {33},
number = {6},
pages = {063607},
year = {2021},
doi = {10.1063/5.0052524},

URL = { 
        https://doi.org/10.1063/5.0052524
    
},
eprint = { 
        https://doi.org/10.1063/5.0052524
}
}

@article{garratt1994atmospheric,
  title={The atmospheric boundary layer},
  author={Garratt, John Roy},
  journal={Earth-Science Reviews},
  volume={37},
  number={1-2},
  pages={89--134},
  year={1994},
  publisher={Elsevier}
}

@article{spalart2011drag,
  title={Drag reduction: enticing turbulence, and then an industry},
  author={Spalart, Philippe R and McLean, J Douglas},
  journal={Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={369},
  number={1940},
  pages={1556--1569},
  year={2011},
  publisher={The Royal Society Publishing}
}


@article{celik2001large,
  title={Large eddy simulations of in-cylinder turbulence for internal combustion engines: a review},
  author={Celik, I and Yavuz, I and Smirnov, A},
  journal={International Journal of Engine Research},
  volume={2},
  number={2},
  pages={119--148},
  year={2001},
  publisher={SAGE Publications Sage UK: London, England}
}


@article{schneider2004hypersonic,
  title={Hypersonic laminar--turbulent transition on circular cones and scramjet forebodies},
  author={Schneider, Steven P},
  journal={Progress in Aerospace Sciences},
  volume={40},
  number={1-2},
  pages={1--50},
  year={2004},
  publisher={Elsevier}
}


@article{stein1976turbulent,
  title={Turbulent blood flow in the ascending aorta of humans with normal and diseased aortic valves.},
  author={Stein, Paul D and Sabbah, Hani N},
  journal={Circulation research},
  volume={39},
  number={1},
  pages={58--65},
  year={1976},
  publisher={Am Heart Assoc}
}


@article{churchfield2012numerical,
  title={A numerical study of the effects of atmospheric and wake turbulence on wind turbine dynamics},
  author={Churchfield, Matthew J and Lee, Sang and Michalakes, John and Moriarty, Patrick J},
  journal={Journal of {T}urbulence},
  number={13},
  pages={N14},
  year={2012},
  publisher={Taylor \& Francis}
}


@article{GARNIER2021104973,
title = {A review on deep reinforcement learning for fluid mechanics},
journal = {Computers \& Fluids},
volume = {225},
pages = {104973},
year = {2021},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2021.104973},
url = {https://www.sciencedirect.com/science/article/pii/S0045793021001407},
author = {Paul Garnier and Jonathan Viquerat and Jean Rabault and Aurélien Larcher and Alexander Kuhnle and Elie Hachem},
keywords = {Deep reinforcement learning, Fluid mechanics},
abstract = {Deep reinforcement learning (DRL) has recently been adopted in a wide range of physics and engineering domains for its ability to solve decision-making problems that were previously out of reach due to a combination of non-linearity and high dimensionality. In the last few years, it has spread in the field of computational mechanics, and particularly in fluid dynamics, with recent applications in flow control and shape optimization. In this work, we conduct a detailed review of existing DRL applications to fluid mechanics problems. In addition, we present recent results that further illustrate the potential of DRL in Fluid Mechanics. The coupling methods used in each case are covered, detailing their advantages and limitations. Our review also focuses on the comparison with classical methods for optimal control and optimization. Finally, several test cases are described that illustrate recent progress made in this field. The goal of this publication is to provide an understanding of DRL capabilities along with state-of-the-art applications in fluid dynamics to researchers wishing to address new problems with these methods.}
}

@article{degrave2022magnetic,
  title={Magnetic control of tokamak plasmas through deep reinforcement learning},
  author={Degrave, Jonas and Felici, Federico and Buchli, Jonas and Neunert, Michael and Tracey, Brendan and Carpanese, Francesco and Ewalds, Timo and Hafner, Roland and Abdolmaleki, Abbas and de Las Casas, Diego and others},
  journal={Nature},
  volume={602},
  number={7897},
  pages={414--419},
  year={2022},
  publisher={Nature Publishing Group}
}


@article{rabault2020deep,
  title={Deep reinforcement learning in fluid mechanics: A promising method for both active flow control and shape optimization},
  author={Rabault, Jean and Ren, Feng and Zhang, Wei and Tang, Hui and Xu, Hui},
  journal={Journal of Hydrodynamics},
  volume={32},
  number={2},
  pages={234--246},
  year={2020},
  publisher={Springer}
}


@article{Korb_2021,
	doi = {10.1088/1742-6596/1934/1/012022},
	url = {https://doi.org/10.1088/1742-6596/1934/1/012022},
	year = 2021,
	month = {may},
	publisher = {{IOP} Publishing},
	volume = {1934},
	number = {1},
	pages = {012022},
	author = {Henry Korb and Henrik Asmuth and Merten Stender and Stefan Ivanell},
	title = {Exploring the application of reinforcement learning to wind farm control},
	journal = {Journal of Physics: Conference Series},
	abstract = {Optimal control of wind farms to maximize power is a challenging task since the wake interaction between the turbines is a highly nonlinear phenomenon. In recent years the field of Reinforcement Learning has made great contributions to nonlinear control problems and has been successfully applied to control and optimization in 2D laminar flows. In this work, Reinforcement Learning is applied to wind farm control for the first time to the authors’ best knowledge. To demonstrate the optimization abilities of the newly developed framework, parameters of an already existing control strategy, the helix approach, are tuned to optimize the total power production of a small wind farm. This also includes an extension of the helix approach to multiple turbines. Furthermore, it is attempted to develop novel control strategies based on the control of the generator torque. The results are analysed and difficulties in the setup in regards to Reinforcement Learning are discussed. The tuned helix approach yields a total power increase of 6.8% on average for the investigated case, while the generator torque controller does not yield an increase in total power. Finally, an alternative setup is proposed to improve the design of the problem.}
}

@Article{fluids7020062,
AUTHOR = {Vinuesa, Ricardo and Lehmkuhl, Oriol and Lozano-Durán, Adrian and Rabault, Jean},
TITLE = {Flow Control in Wings and Discovery of Novel Approaches via Deep Reinforcement Learning},
JOURNAL = {Fluids},
VOLUME = {7},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {62},
URL = {https://www.mdpi.com/2311-5521/7/2/62},
ISSN = {2311-5521},
ABSTRACT = {In this review, we summarize existing trends of flow control used to improve the aerodynamic efficiency of wings. We first discuss active methods to control turbulence, starting with flat-plate geometries and building towards the more complicated flow around wings. Then, we discuss active approaches to control separation, a crucial aspect towards achieving a high aerodynamic efficiency. Furthermore, we highlight methods relying on turbulence simulation, and discuss various levels of modeling. Finally, we thoroughly revise data-driven methods and their application to flow control, and focus on deep reinforcement learning (DRL). We conclude that this methodology has the potential to discover novel control strategies in complex turbulent flows of aerodynamic relevance.},
DOI = {10.3390/fluids7020062}
}




@article{henry2021deep,
  title={Deep reinforcement learning for dynamic control of fuel injection timing in multi-pulse compression ignition engines},
  author={Henry de Frahan, Marc T and Wimer, Nicholas T and Yellapantula, Shashank and Grout, Ray W},
  journal={International Journal of Engine Research},
  pages={14680874211019345},
  year={2021},
  publisher={SAGE Publications Sage UK: London, England}
}


@article{bucci2019control,
  title={Control of chaotic systems by deep reinforcement learning},
  author={Bucci, Michele Alessandro and Semeraro, Onofrio and Allauzen, Alexandre and Wisniewski, Guillaume and Cordier, Laurent and Mathelin, Lionel},
  journal={Proceedings of the Royal Society A},
  volume={475},
  number={2231},
  pages={20190351},
  year={2019},
  publisher={The Royal Society Publishing}
}


@article{beintema2020controlling,
  title={Controlling Rayleigh--B{\'e}nard convection via reinforcement learning},
  author={Beintema, Gerben and Corbetta, Alessandro and Biferale, Luca and Toschi, Federico},
  journal={Journal of Turbulence},
  volume={21},
  number={9-10},
  pages={585--605},
  year={2020},
  publisher={Taylor \& Francis}
}


@article{belus2019exploiting,
  title={Exploiting locality and translational invariance to design effective {DRL} control of the 1-dimensional unstable falling liquid film},
  author={Belus, Vincent and Rabault, Jean and Viquerat, Jonathan and Che, Zhizhao and Hachem, Elie and Reglade, Ulysse},
  journal={AIP Advances},
  volume={9},
  number={12},
  pages={125014},
  year={2019},
  publisher={AIP Publishing LLC}
}


@article{fan2020reinforcement,
  title={Reinforcement learning for bluff body active flow control in experiments and simulations},
  author={Fan, Dixia and Yang, Liu and Wang, Zhicheng and Triantafyllou, Michael S and Karniadakis, George Em},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={42},
  pages={26091--26098},
  year={2020},
  publisher={National Acad Sciences}
}


@article{paris2021robust,
  title={Robust flow control and optimal sensor placement using deep reinforcement learning},
  author={Paris, Romain and Beneddine, Samir and Dandois, Julien},
  journal={Journal of Fluid Mechanics},
  volume={913},
  year={2021},
  publisher={Cambridge University Press}
}


@article{xu2020active,
  title={Active flow control with rotating cylinders by an artificial neural network trained by deep reinforcement learning},
  author={Xu, Hui and Zhang, Wei and Deng, Jian and Rabault, Jean},
  journal={Journal of Hydrodynamics},
  volume={32},
  number={2},
  pages={254--258},
  year={2020},
  publisher={Springer}
}


@article{ren2021applying,
  title={Applying deep reinforcement learning to active flow control in weakly turbulent conditions},
  author={Ren, Feng and Rabault, Jean and Tang, Hui},
  journal={Physics of Fluids},
  volume={33},
  number={3},
  pages={037121},
  year={2021},
  publisher={AIP Publishing LLC}
}


@article{rabault2019accelerating,
  title={Accelerating deep reinforcement learning strategies of flow control through a multi-environment approach},
  author={Rabault, Jean and Kuhnle, Alexander},
  journal={Physics of Fluids},
  volume={31},
  number={9},
  pages={094105},
  year={2019},
  publisher={AIP Publishing LLC}
}

@article{Vignon_2023,
	doi = {10.1063/5.0153181},
  
	url = {https://doi.org/10.1063%2F5.0153181},
  
	year = 2023,
  
	publisher = {{AIP} Publishing},
  
	volume = {35},
  
	number = {6},
  
	author = {Vignon, C. and Rabault, J. and Vasanth, J. and Alc{\'{a}}ntara-{\'{A}}vila, F. and Mortensen, M. and Vinuesa R.},
  
	title = {Effective control of two-dimensional Rayleigh{\textendash}B{\'{e}}nard convection: Invariant multi-agent reinforcement learning is all you need},
  
	journal = {Physics of Fluids}
}

@article{rabault,
  title={Artificial neural networks trained through deep reinforcement learning discover control strategies for active flow control},
  author={Rabault, J. and Kuchta, M. and Jensen, A. and R{\'e}glade, U. and Cerardi, N.},
  journal={Journal of Fluid Mechanics},
  volume={865},
  pages={281--302},
  year={2019},
  publisher={Cambridge University Press}
}

@article{novati,
  author    = {Guido Novati and Hugues Lascombes de Laroussilhe and Petros Koumoutsakos
  },
  title     = {Automating Turbulence Modeling by Multi-Agent Reinforcement Learning},
  journal   = {Nature Machine Intelligence},
  pages = {87--96},
  volume    = {3},
  year      = {2021}
}

@misc{tensorforce,
  author       = {Kuhnle, Alexander and Schaarschmidt, Michael and Fricke, Kai},
  title        = {Tensorforce: a TensorFlow library for applied reinforcement learning},
  howpublished = {Web page},
  url          = {https://github.com/tensorforce/tensorforce},
  year         = {2017}
}

@techreport{chevalier,
  title={A pseudospectral solver for incompressible boundary layer flows},
  author={Chevalier, M. and Schlatter, P. and Lundbladh, A. and Henningson, D. S.},
  year={2007},
  institution={TRITA-MEK 2007:07. KTH Mechanics, Stockholm, Sweden},
  type={},
}

@article{vignon,
author = {Vignon, C.  and Rabault, J. and Vinuesa, R. },
title = {Recent advances in applying deep reinforcement learning for flow control: Perspectives and future directions},
journal = {Physics of Fluids},
volume = {35},
number = {3},
pages = {031301},
year = {2023},
doi = {10.1063/5.0143913}
}

@Article{Guastoni2023,
author={Guastoni, Luca
and Rabault, Jean
and Schlatter, Philipp
and Azizpour, Hossein
and Vinuesa, Ricardo},
title={Deep reinforcement learning for turbulent drag reduction in channel flows},
journal={The European Physical Journal E},
year={2023},
volume={46},
number={4},
pages={27},
abstract={We introduce a reinforcement learning (RL) environment to design and benchmark control strategies aimed at reducing drag in turbulent fluid flows enclosed in a channel. The environment provides a framework for computationally efficient, parallelized, high-fidelity fluid simulations, ready to interface with established RL agent programming interfaces. This allows for both testing existing deep reinforcement learning (DRL) algorithms against a challenging task, and advancing our knowledge of a complex, turbulent physical system that has been a major topic of research for over two centuries, and remains, even today, the subject of many unanswered questions. The control is applied in the form of blowing and suction at the wall, while the observable state is configurable, allowing to choose different variables such as velocity and pressure, in different locations of the domain. Given the complex nonlinear nature of turbulent flows, the control strategies proposed so far in the literature are physically grounded, but too simple. DRL, by contrast, enables leveraging the high-dimensional data that can be sampled from flow simulations to design advanced control strategies. In an effort to establish a benchmark for testing data-driven control strategies, we compare opposition control, a state-of-the-art turbulence-control strategy from the literature, and a commonly used DRL algorithm, deep deterministic policy gradient. Our results show that DRL leads to 43{\%} and 30{\%} drag reduction in a minimal and a larger channel (at a friction Reynolds number of 180), respectively, outperforming the classical opposition control by around 20 and 10 percentage points, respectively.},
issn={1292-895X},
doi={10.1140/epje/s10189-023-00285-8},
url={https://doi.org/10.1140/epje/s10189-023-00285-8}
}

@article{opposition, title={Active turbulence control for drag reduction in wall-bounded flows}, volume={262}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Choi, Haecheon and Moin, Parviz and Kim, John}, year={1994}, pages={75–110}}

@article{opposition2,
author = {Hammond,Edward P.  and Bewley,Thomas R. and Moin,Parviz },
title = {Observed mechanisms for turbulence attenuation and enhancement in opposition-controlled wall-bounded flows},
journal = {Physics of Fluids},
volume = {10},
number = {9},
pages = {2421-2423},
year = {1998},
doi = {10.1063/1.869759}
}

@article{opposition3,
author = {Chang,Yong  and Collis,S. Scott  and Ramakrishnan,Srinivas },
title = {Viscous effects in control of near-wall turbulence},
journal = {Physics of Fluids},
volume = {14},
number = {11},
pages = {4069-4080},
year = {2002},
doi = {10.1063/1.1509751}
}

@article{comparison,
author = {Stroh,A.  and Frohnapfel,B.  and Schlatter,P.  and Hasegawa,Y. },
title = {A comparison of opposition control in turbulent boundary layer and turbulent channel flow},
journal = {Physics of Fluids},
volume = {27},
number = {7},
pages = {075101},
year = {2015},
doi = {10.1063/1.4923234}
}

@article{blowing,
author = {Fahland, Georg and Stroh, Alexander and Frohnapfel, Bettina and Atzori, Marco and Vinuesa, Ricardo and Schlatter, Philipp and Gatti, Davide},
title = {Investigation of Blowing and Suction for Turbulent Flow Control on Airfoils},
journal = {AIAA Journal},
volume = {59},
number = {11},
pages = {4422-4436},
year = {2021},
doi = {10.2514/1.J060211}
}

@article{biferale,
author = {Biferale,Luca  and Bonaccorso,Fabio  and Buzzicotti,Michele  and Clark Di Leoni,Patricio  and Gustavsson,Kristian },
title = {Zermelo’s problem: Optimal point-to-point navigation in 2D turbulent flows using reinforcement learning},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
volume = {29},
number = {10},
pages = {103138},
year = {2019},
doi = {10.1063/1.5120370}
}

@article{
swimmers,
author = {Siddhartha Verma  and Guido Novati  and Petros Koumoutsakos },
title = {Efficient collective swimming by harnessing vortices through deep reinforcement learning},
journal = {Proceedings of the National Academy of Sciences},
volume = {115},
number = {23},
pages = {5849-5854},
year = {2018},
doi = {10.1073/pnas.1800923115},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1800923115},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1800923115}}

@article{
kutz,
author = {Steven L. Brunton  and Joshua L. Proctor  and J. Nathan Kutz },
title = {Discovering governing equations from data by sparse identification of nonlinear dynamical systems},
journal = {Proceedings of the National Academy of Sciences},
volume = {113},
number = {15},
pages = {3932-3937},
year = {2016},
doi = {10.1073/pnas.1517384113},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1517384113},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1517384113}}

@article{eivazi,
title = {Recurrent neural networks and Koopman-based frameworks for temporal predictions in a low-order model of turbulence},
author = {Eivazi, H. and Guastoni, L. and Schlatter, P. and Azizpour, H and Vinuesa, R.},
journal = {International Journal of Heat and Fluid Flow},
volume = {90},
pages = {108816},
year = {2021},
issn = {0142-727X},
doi = {https://doi.org/10.1016/j.ijheatfluidflow.2021.108816},
url = {https://www.sciencedirect.com/science/article/pii/S0142727X21000461}}

@article{guastoni,
  title={Convolutional-network models to predict wall-bounded turbulence from wall quantities},
  author={Guastoni, Luca and G{\"u}emes, Alejandro and Ianiro, Andrea and Discetti, Stefano and Schlatter, Philipp and Azizpour, Hossein and Vinuesa, Ricardo},
  journal={Journal of Fluid Mechanics},
  volume={928},
  pages={A27},
  year={2021}
}

@inproceedings{otness,
 author = {Otness, Karl and Gjoka, Arvi and Bruna, Joan and Panozzo, Daniele and Peherstorfer, Benjamin and Schneider, Teseo and Zorin, Denis},
 booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
 editor = {J. Vanschoren and S. Yeung},
 pages = {},
 title = {An Extensible Benchmark Suite for Learning to Simulate Physical Systems},
 url = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/3def184ad8f4755ff269862ea77393dd-Paper-round1.pdf},
 volume = {1},
 year = {2021}
}

@article{FUKAGATA20091082,
title = {On the lower bound of net driving power in controlled duct flows},
journal = {Physica D: Nonlinear Phenomena},
volume = {238},
number = {13},
pages = {1082-1086},
year = {2009},
issn = {0167-2789},
doi = {https://doi.org/10.1016/j.physd.2009.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167278909000840},
author = {Koji Fukagata and Kazuyasu Sugiyama and Nobuhide Kasagi},
keywords = {Incompressible flow, Flow control, Drag reduction, Dissipation}}

@article{sonoda_arxiv,
  author    = {Takahiro Sonoda and Zhuchen Liu and Toshitaka Itoh and Yosuke Hasegawa
  },
  title     = {Reinforcement Learning of Control Strategies for Reducing Skin Friction Drag in a Fully Developed Channel Flow},
  journal   = {arXiv preprint},
  volume    = {arXiv:2206.15355},
  year      = {2022}
}
@article{sonoda, title={Reinforcement learning of control strategies for reducing skin friction drag in a fully developed turbulent channel flow}, volume={960}, DOI={10.1017/jfm.2023.147}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Sonoda, Takahiro and Liu, Zhuchen and Itoh, Toshitaka and Hasegawa, Yosuke}, year={2023}, pages={A30}}


@article{pettingzoo,
  author    = {Justin K. Terry and
               Benjamin Black and
               Ananth Hari and
               Luis S. Santos and
               Clemens Dieffendahl and
               Niall L. Williams and
               Yashas Lokesh and
               Caroline Horsch and
               Praveen Ravi},
  title     = {PettingZoo: Gym for Multi-Agent Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2009.14471},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.14471},
  eprinttype = {arXiv},
  eprint    = {2009.14471}
}

@article{wallace_eckelmann_brodkey_1972, title={The wall region in turbulent shear flow}, volume={54}, DOI={10.1017/S0022112072000515}, number={1}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Wallace, James M. and Eckelmann, Helmut and Brodkey, Robert S.}, year={1972}, pages={39–48}}

@article{lu_willmarth_1973, title={Measurements of the structure of the Reynolds stress in a turbulent boundary layer}, volume={60}, DOI={10.1017/S0022112073000315}, number={3}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Lu, S. S. and Willmarth, W. W.}, year={1973}, pages={481–511}}

@article{jimenez-minimal, title={The minimal flow unit in near-wall turbulence}, volume={225}, DOI={10.1017/S0022112091002033}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Jiménez, Javier and Moin, Parviz}, year={1991}, pages={213–240}}

@misc{ddpg,
    author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
    keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {Continuous control with deep reinforcement learning},
    journal = {arXiv preprint - arXiv:1509.02971},
    year = {2015}
}

@article{kurz-modelling,
title = {Deep reinforcement learning for turbulence modeling in large eddy simulations},
journal = {International Journal of Heat and Fluid Flow},
volume = {99},
pages = {109094},
year = {2023},
issn = {0142-727X},
doi = {https://doi.org/10.1016/j.ijheatfluidflow.2022.109094},
url = {https://www.sciencedirect.com/science/article/pii/S0142727X2200162X},
author = {Marius Kurz and Philipp Offenhäuser and Andrea Beck},
keywords = {Turbulence modeling, Deep reinforcement learning, Large eddy simulation},
}

@article{park_choi_2020, title={Machine-learning-based feedback control for drag reduction in a turbulent channel flow}, volume={904}, DOI={10.1017/jfm.2020.690}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Park, Jonghwan and Choi, Haecheon}, year={2020}, pages={A24}}

@book{mlc,
author    = "Duriez,Thomas and Brunton, Steven L. and Noack, Bernd R.",
title     = "Machine Learning Control – Taming Nonlinear Dynamics and Turbulence",
year      = "2017",
publisher = "Springer"
}

@article{kim_moin_moser_1987, title={Turbulence statistics in fully developed channel flow at low Reynolds number}, volume={177}, DOI={10.1017/S0022112087000892}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Kim, John and Moin, Parviz and Moser, Robert}, year={1987}, pages={133–166}}

@misc{pino,
  doi = {10.48550/ARXIV.2202.11664},
  
  author = {Pino, Fabio and Schena, Lorenzo and Rabault, Jean and Mendez, Miguel A.},
  
  title = {Comparative analysis of machine learning methods for active flow control},
  
  publisher = {arXiv},
  
  year = {2022}
}


@article{stable,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@article{marusic,
  author  = {Ivan Marusic and Dileep Chandran and Amirreza Rouhi and Matt K. Fu and David Wine and Brian Holloway and Daniel Chung and Alexander J. Smits},
  title   = {An energy-efficient pathway to turbulent drag reduction}
  ,
  journal = {Nature Communications},
  year    = {2021},
  volume  = {12},
  number  = {5805}
}

@misc{anandkumar,  
  author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  
  title = {Fourier Neural Operator for Parametric Partial Differential Equations},
  
  journal = {arXiv preprint - arXiv:2010.08895},
  

  year = {2020}
}

@article{hoyer,
	year = 2021,
	month = {may},
  
	publisher = {Proceedings of the National Academy of Sciences},
  
	volume = {118},
  
	number = {21},
  
	author = {Dmitrii Kochkov and Jamie A. Smith and Ayya Alieva and Qing Wang and Michael P. Brenner and Stephan Hoyer},
  
	title = {Machine learning{\textendash}accelerated computational fluid dynamics},
  
	journal = {Proceedings of the National Academy of Sciences}
}

@article{eivazi-ae,
	title = {Towards extraction of orthogonal and parsimonious non-linear modes from turbulent flows},
	author = {Eivazi, H. and Le Clainche, S. and Hoyas, S. and Vinuesa, R.},
	year = {2022},
	journal={Expert Systems with Applications},
	volume={202},
	pages = {117038}
}

@article{enhancing,
  author  = {Ricardo Vinuesa and Steve Brunton},
  title   = {Enhancing computational fluid dynamics with machine learning}
  ,
  journal = {Nature Computational Science},
  year    = {2022},
  volume  = {2},
  pages  = {358--366}
}

@misc{emerging,
  author = {Vinuesa, Ricardo and Brunton, Steve},  
  title = {Emerging trends in machine learning for computational fluid dynamics},
  
  journal = {arXiv preprint - arXiv:2211.15145},
  
  year = {2022}
}

@article{fukami-super, title={Super-resolution reconstruction of turbulent flows with machine learning}, volume={870}, DOI={10.1017/jfm.2019.238}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Fukami, Kai and Fukagata, Koji and Taira, Kunihiko}, year={2019}, pages={106–120}}

@article{guemes-gans,
author = {Güemes,A.  and Discetti,S.  and Ianiro,A.  and Sirmacek,B.  and Azizpour,H.  and Vinuesa,R. },
title = {From coarse wall measurements to turbulent velocity fields through deep learning},
journal = {Physics of Fluids},
volume = {33},
number = {7},
pages = {075121},
year = {2021},
doi = {10.1063/5.0058346},

URL = { 
        https://doi.org/10.1063/5.0058346
    
},
eprint = { 
        https://doi.org/10.1063/5.0058346
    
}

}

@article{zeng,
author = {Zeng, Kevin  and Linot, Alec J.  and Graham, Michael D. },
title = {Data-driven control of spatiotemporal chaos with reduced-order neural {ODE}-based models and reinforcement learning},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
volume = {478},
number = {2267},
pages = {20220297},
year = {2022},
doi = {10.1098/rspa.2022.0297}}

@Article{varela,
AUTHOR = {Varela, Pau and Suárez, Pol and Alcántara-Ávila, Francisco and Miró, Arnau and Rabault, Jean and Font, Bernat and García-Cuevas, Luis Miguel and Lehmkuhl, Oriol and Vinuesa, Ricardo},
TITLE = {Deep Reinforcement Learning for Flow Control Exploits Different Physics for Increasing {R}eynolds Number Regimes},
JOURNAL = {Actuators},
VOLUME = {11},
YEAR = {2022},
NUMBER = {12},
ARTICLE-NUMBER = {359},
URL = {https://www.mdpi.com/2076-0825/11/12/359},
ISSN = {2076-0825},
DOI = {10.3390/act11120359}
}

@article{linot,
author = {Linot,Alec J.  and Graham,Michael D. },
title = {Data-driven reduced-order modeling of spatiotemporal chaos with neural ordinary differential equations},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
volume = {32},
number = {7},
pages = {073110},
year = {2022},
doi = {10.1063/5.0069536},

URL = { 
        https://doi.org/10.1063/5.0069536
    
},
eprint = { 
        https://doi.org/10.1063/5.0069536
    
}

}

@article{moehlis_et_al,
Author = {Moehlis, J. and Faisst, H. and Eckhardt, B.},
Journal = {New J. Phys.},
Pages = {56},
Title = {A low-dimensional model for turbulent shear flows},
Volume = {6},
Year = {2004}}

@book{canuto,
Author = {Canuto, C., Hussaini, M.~Y., Quarteroni, A. \& Zang, T.~A.},
Title = {Spectral
  Methods in Fluids Dynamics},
editor = {Springer},
year = {1988}
}

@misc{guastoni_DRL,
  doi = {10.48550/ARXIV.2301.09889},
  
  url = {https://arxiv.org/abs/2301.09889},
  
  author = {Guastoni, L. and Rabault, J. and Schlatter, P. and Azizpour, H. and Vinuesa, R.},
  
  keywords = {Fluid Dynamics (physics.flu-dyn), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Deep reinforcement learning for turbulent drag reduction in channel flows},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{lorsung2023,
author = {Lorsung,Cooper  and Barati Farimani,Amir },
title = {Mesh deep {Q} network: A deep reinforcement learning framework for improving meshes in computational fluid dynamics},
journal = {AIP Advances},
volume = {13},
number = {1},
pages = {015026},
year = {2023},
doi = {10.1063/5.0138039},

URL = { 
        https://doi.org/10.1063/5.0138039
    
},
eprint = { 
        https://doi.org/10.1063/5.0138039
    
}

}

@article{biferale,
author = {Biferale,Luca  and Bonaccorso,Fabio  and Buzzicotti,Michele  and Clark Di Leoni,Patricio  and Gustavsson,Kristian },
title = {Zermelo’s problem: optimal point-to-point navigation in 2{D} turbulent flows using reinforcement learning},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
volume = {29},
number = {10},
pages = {103138},
year = {2019},
doi = {10.1063/1.5120370}
}

@article{
swimmers,
author = {Siddhartha Verma  and Guido Novati  and Petros Koumoutsakos },
title = {Efficient collective swimming by harnessing vortices through deep reinforcement learning},
journal = {Proceedings of the National Academy of Sciences},
volume = {115},
number = {23},
pages = {5849-5854},
year = {2018},
doi = {10.1073/pnas.1800923115},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1800923115},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1800923115}}

@article{kurz-modelling,
title = {Deep reinforcement learning for turbulence modeling in large eddy simulations},
journal = {International Journal of Heat and Fluid Flow},
volume = {99},
pages = {109094},
year = {2023},
issn = {0142-727X},
doi = {https://doi.org/10.1016/j.ijheatfluidflow.2022.109094},
url = {https://www.sciencedirect.com/science/article/pii/S0142727X2200162X},
author = {Marius Kurz and Philipp Offenhäuser and Andrea Beck},
keywords = {Turbulence modeling, Deep reinforcement learning, Large eddy simulation},
}

@article{guseva_jimenez_2022, title={Linear instability and resonance effects in large-scale opposition flow control}, volume={935}, DOI={10.1017/jfm.2022.34}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Guseva, Anna and Jiménez, Javier}, year={2022}, pages={A35}}

@article{gym,
  title={Open{AI} {G}ym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
} 

@article{novati,
  author    = {Guido Novati and Hugues Lascombes de Laroussilhe and Petros Koumoutsakos
  },
  title     = {Automating Turbulence Modeling by Multi-Agent Reinforcement Learning},
  journal   = {Nature Machine Intelligence},
  pages = {87--96},
  volume    = {3},
  year      = {2021}
}
