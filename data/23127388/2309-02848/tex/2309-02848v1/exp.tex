\section{Experiment}
\subsection{Experiment setup}
\textbf{Dataset.} We conduct experiments on three public and real-world datasets, which are Ogbn-arxiv\cite{hu2020open} (shorted as Arxiv), Instagram\cite{kim2020multimodal}, and Reddit\footnote{\url{https://convokit.cornell.edu/documentation/subreddit.html}}, to evaluate the effectiveness of the proposed method G-Prompt. Specifically, Ogbn-arxiv is a citation network where edges represent citation relationships, nodes represent papers and the text attribute is the abstracts of papers. The task on this graph is to predict paper subjects. Instagram is a social network where edges represent following relationships, nodes represent users, and the prediction task is to classify commercial users and normal users in this network. The text attribute is the users' profile. Reddit is also a social network where each node denotes a user, the node features are the content of users' historically published subreddits, and edges denote whether two users have replied to each other. The prediction task is to classify whether a user is in the top 50\% popular (average score of all subreddits). Table 1 shows detailed statistics of these datasets. More details about Instagram and Reddit are provided in the Appendix.

\textbf{Evaluate: compare different representations generated by different methods. } We compare the proposed G-Prompt with PLM-based and Graph-based node feature-extracting methods. For the PLM-based methods, we consider three options: (1) direct use of sentence embedding as node features, and (2) use of the hidden states of masked tokens based on hard prompts as node features. (3) use of the prediction result of masked tokens based on prompts as node feature. For graph-based methods, we compare our proposed method with GAE and GIANT, which first conduct self-supervised learning on graphs to train PLMs or node feature encoders. To ensure a fair comparison, we add prompts into graph-based baselines. Except for GAINT and OGB features, the PLM we use in this paper is RoBERTa-Large\cite{liu2019roberta}. Note that all prompts used in baselines are the same as those in G-Prompt.

\textbf{Implementation details.} For G-Prompt, we first train three graph adapters of G-Prompt on Arxiv, Instagram, and Reddit with 50 epochs, 100 epochs, and 100 epochs respectively. All of them are optimized using AdamW\cite{loshchilov2017decoupled} with warm-up. For more details on the hyper-parameter settings, please refer to the Appendix. For each node, we replace 10\% tokens with [mask] and use these masked tokens to train the graph adapter. During the whole training stage, all task-related prompts are invisible. Then we use prompts, finetuned graph adapters, and PLMs to jointly extract node features. For graph-based methods, we train them on each dataset with searched hyper-parameters.

\begin{table}[t!]
  \caption{ Statistics of the  datasets}
    \label{Table:dataset}
  \centering
\resizebox{0.7\textwidth}{!}{
      \begin{tabular}{cccccc}
        \toprule
        
        \textbf{Dataset}&\textbf{\# Nodes} &\textbf{\# Eeges}&\textbf{Avg. Node Degree}&\textbf{Test Ratio (\%)}&\textbf{Metric} \\ 
         \hline
        \textbf{Arxiv}& 169,343& 1,166,243& 13.7&28&ACC\\
        \textbf{Instagram}& 11,339 &377,812& 66.6& 60&ROC\\
        \textbf{Reddit}&33,434&198,448&11.9& 33&ROC\\

        %\cmidrule(r){1-5}
        \bottomrule
      \end{tabular}
      }
\end{table}
\subsection{Few-shot learning}

To evaluate the performance of representations generated by different methods in few-shot learning, we compare the performance of different representations at different shot numbers based on the same GNN backbone. The GNN backbone used in the performance comparison on different shot numbers is GraphSAGE\cite{velivckovic2017graph}. In addition, we also compare the performance of different representations combined with three different neural network architectures (i.e., MLP, and RevGAT\cite{li2021training}) on downstream tasks with the same number of shots. For Arxiv, we use a publicly available partitioned test set, while for Instagram and Reddit, we randomly sample 60\% and 33\% of the data as the test sets, respectively. To consider the randomness of partitioning and training, each experimental result is based on five random partitions (the partitions are the same for different baselines), the experiment is repeated five times for each partition, and the variance of 5$\times$5 results is reported.

The experiment results on different shots-num are shown in Table 2. The experiment shows that: (1) \textbf{Graph Information can improve the performance of node representation}. In general, approaches that use sentence representations or those that involve self-supervised training with graph information tend to outperform non-trained representations. For example, GAE shows an average improvement of \textit{avg.} 6.2\% compared to RoBERTa's [cls], and GIANT shows \textit{avg.} 6.2\% improvement over cls representation. For graph-based self-supervised tasks, fine-tuning language models might be more suitable for larger datasets. GIANT outperforms GAE by \textit{avg.} 3.0\% on Arxiv, but lags behind by \textit{avg.} 1.4\% on Instagram and Reddit.
(2) 
\textbf{Downstream task-related prompts can improve performance for most methods}. For graph-free language models, prompt-based representations can improve performance by \textit{avg.} 5.7\%, and the overall performance of prediction values and hidden states corresponding to prompts is similar. For graph-based methods, prompts in GAE improve performance by \textit{avg.} 1.3\%, while prompts in GIANT lead to an average improvement of \textit{avg.} 1.2\%. However, we note that prompts are unstable for graph-based pre-trained models. GAE shows a decline in 4 experiments, while prompts only bring a slight improvement in GIANT (compared to language models).
(3) \textbf{Our method is capable of utilizing both graph information and downstream task prompts simultaneously}, achieving state-of-the-art performance. Compared to PLM representations without prompts, our method improves by \textit{avg.} 10.6\%. Compared to PLM-prompt, it improves by \textit{avg.} 4.6\%, and compared to GIANT, it improves by \textit{avg.} 4.1\%.

Besides, we also compared these methods under different GNN backbone. as Figure 2 shows, the node representation extracted by G-Prompt in different GNN-backbone also achieves the SOTA performance compared to other baseline methods. 

\begin{table}[t!]
\caption{The performance in different shots on three datasets. Each row corresponds to a specific method. Every column lists the performance of the models in specific the shot number per class of the dataset   (mean ± std\%, the best results are bolded and the runner-ups are underlined). Accuracy is used as evaluation metric for the task in Arxiv while AUC is used as evaluation metric for the other two datasets.}
\label{table:table}
\setlength{\tabcolsep}{0.5mm} 
\renewcommand{\arraystretch}{0.85}
\centering
\resizebox{1.0\textwidth}{!}{
\begin{tabular}{c|ccc|ccc|ccc}

\toprule
{\textbf{Dataset}} & \multicolumn{3}{c|}{\textbf{Arxiv}} & \multicolumn{3}{c|}{\textbf{Instagram}} & \multicolumn{3}{c}{\textbf{Reddit}} \\
%\cmidrule(r){1-5}
\# shots per class & 10 & 50 &100 & 10 & 50 &100 & 10 & 50 &100 \\
\midrule


\renewcommand{\arraystretch}{0.85}
\thead{ OGB-Feature} & \thead{0.4576  \tiny{(0.0324)}} & \thead{0.5495  \tiny{(0.0171)}}&\thead{ 0.5875  \tiny{(0.0146)}} & -&-&-&-&-&-\\

    
\thead{ PLM+GAE} & \thead{0.5016  \tiny{(0.0510)} }& \thead{ 0.5608  \tiny{(0.0101)}} & \thead{0.5810  \tiny{(0.0125)} } &\thead{ 0.5258  \tiny{(0.0635)}} & \thead{0.5818 \tiny{(0.0101)} }& \thead{0.5821 \tiny{(0.0058)}} & \thead{ 0.5653  \tiny{(0.0256)} }& \thead{0.6019 \tiny{(0.0174)} }& \thead{0.6154  \tiny{(0.0128)}}\\

    
\thead{ PLM+GAE+prompt} &\thead{0.5189  \tiny{(0.0333)} }& \thead{ 0.5801  \tiny{(0.0102)}} & \thead{0.6063  \tiny{(0.0109)} } &\thead{ 0.5418  \tiny{(0.0298)}} & \thead{0.5705  \tiny{(0.0233)} }& \thead{0.5867 \tiny{(0.0100)}} & \thead{ 0.5619  \tiny{(0.0425)} }& \thead{0.5968 \tiny{(0.0237)} }& \thead{0.6173  \tiny{(0.0160)}}\\
    
    \thead{ GIANT} & \thead{0.5050  \tiny{(0.0308)} }& \thead{ 0.5798  \tiny{(0.0119)}} & \thead{0.6081  \tiny{(0.0109)} } &\thead{ 0.5185  \tiny{(0.0323)}} & \thead{0.5601  \tiny{(0.0304)} }& \thead{0.5752 \tiny{(0.0251)}} & \thead{ 0.5618  \tiny{(0.0431)} }& \thead{0.5954 \tiny{(0.0131)} }& \thead{0.6130 
    \tiny{(0.0117)}}\\

     
    \thead{ GIANT + prompt} & \thead{0.5140  \tiny{(0.0320)} }& \thead{ 0.5809  \tiny{(0.0223)}} & \thead{0.6126  \tiny{(0.0159)} } &\thead{ 0.5239  \tiny{(0.0309)}} & \thead{0.5721  \tiny{(0.0361)} }& \thead{0.5949 \tiny{(0.0089)}} & \thead{ 0.5661  \tiny{(0.0459)} }& \thead{0.5968 \tiny{(0.0096)} }& \thead{0.6145  \tiny{(0.0105)}}\\
    \hline
    PLM-cls & \thead{0.4697  \tiny{(0.0577)} }& \thead{ 0.5414  \tiny{(0.0400)}} & \thead{0.5869  \tiny{(0.0300)} } &\thead{ 0.5165  \tiny{(0.0217)}} & \thead{0.5385  \tiny{(0.0344) }}& \thead{0.5690 \tiny{(0.0253)}} & \thead{ 0.4965  \tiny{(0.0373)} }& \thead{0.5236 \tiny{(0.0394)} }& \thead{0.5754  \tiny{(0.0348)}}\\

  
    \thead{ PLM-Prompt-dense} & \thead{0.5117  \tiny{(0.0398)} }& \thead{ 0.5631  \tiny{(0.0352)}} & \thead{0.5865  \tiny{(0.0296)} } &\thead{ 0.5458  \tiny{(0.0420)}} & \thead{0.5796  \tiny{(0.0276)} }& \thead{\underline{0.6055 \tiny{(0.0122)}}} & \thead{ 0.5363  \tiny{(0.0530)} }& \thead{0.5648 \tiny{(0.0385)} }& \thead{0.5998 \tiny{(0.0383)}}
                   \\

                   
    \thead{ PLM-Prompt-sparse} & \thead{0.5201  \tiny{(0.0284)} }& \thead{ 0.5784  \tiny{(0.0213)}} & \thead{0.6085  \tiny{(0.0203)} } &\thead{ 0.5363  \tiny{(0.0348)}} & \thead{0.5757  \tiny{(0.0225)} }& \thead{0.5910 \tiny{(0.0229)}} & \thead{ 0.5403  \tiny{(0.0424)} }& \thead{0.5761 \tiny{(0.0359)} }& \thead{0.6082  \tiny{(0.0192)}}\\
               \hline 
             
  
      % \thead{G-Prompt \\ } & \thead{0.5232 \\ \scriptsize{$\pm$0.0348} }& \thead{ \underline{0.5909} \\ \underline{\scriptsize{$\pm$0.0159}}} & \thead{\textbf{0.6240$^*$} \\ \textbf{\scriptsize{$\pm$0.0156}} } &\thead{ \underline{0.5519} \\ \underline{\scriptsize{$\pm$0.0355}}} & \thead{\underline{0.5787} \\ \underline{\scriptsize{$\pm$0.0333}} }& \thead{\underline{0.6084} \\\underline{\scriptsize{$\pm$0.0127}}} & \thead{ \textbf{0.5794$^*$} \\ \textbf{\scriptsize{$\pm$0.0495}} }& \thead{\underline{0.6149} \\\underline{\scriptsize{$\pm$0.0270} }}& \thead{\underline{0.6427} \\ \underline{\scriptsize{$\pm$0.0185}}}\\
      
      \thead{G-Prompt} & \thead{\underline{0.5248 \tiny{(0.0382)}} }& \thead{ \textbf{0.5927}  \textbf{\tiny{(0.0142)}}} & \thead{\underline{0.6167  \tiny{(0.0138)}}}  &\thead{ \textbf{0.5576}  \textbf{\tiny{(0.0330)}}} & \thead{\textbf{0.5917} \textbf{\tiny{(0.0242)}} }& \thead{\textbf{0.6090} \textbf{\tiny{(0.0135)}}} & \thead{ \textbf{0.5728} \textbf{\tiny{(0.0491)}} }& \thead{\textbf{0.6167} \textbf{\tiny{(0.0289)}} }& \thead{\textbf{0.6472} \textbf{\tiny{(0.0224)}}}\\

     \hline
     
 \thead{G-Prompt  w/o gate} & \thead{\textbf{0.5291}  \textbf{\tiny{(0.0315)}} }& \thead{ 0.5877 \tiny{(0.0192)}} & \thead{\textbf{0.6212} \textbf{\tiny{(0.0190)}} } &\thead{ \underline{0.5507 \tiny{(0.0336)}}} & \thead{0.5706  \tiny{(0.0262)} }& \thead{0.5942 \tiny{(0.0178)}} & \thead{ 0.5501  \tiny{(0.0604)} }& \thead{\underline{0.5926 \tiny{(0.0385)}} }& \thead{\underline{0.6361 \tiny{(0.0268)}}}\\

     

   
     
    \thead{G-Prompt w/o graph} & \thead{0.5226 \tiny{(0.0322)}} & \thead{\underline{0.5880 \tiny{(0.0168)}}} & \thead{0.6059 \tiny{(0.0101)}} \
     & \thead{0.5234 \tiny{(0.0236)}} & \thead{0.5657 \tiny{(0.0377)}} & \thead{0.5914 \tiny{(0.0199)}}     & \thead{\underline{0.5536  \tiny{(0.0438)}}} & \thead{0.5683  \tiny{(0.0390)}} & \thead{0.6054 \tiny{(0.0263)}} \\ 

     
    \thead{G-Prompt w/o SSL} & \thead{0.5210  \tiny{(0.0372)}} & \thead{0.5793  \tiny{(0.0168)}} & \thead{0.6092  \tiny{(0.0168)}} \
     & \thead{0.5378  \tiny{(0.0419)}} & \thead{\underline{0.5801 \tiny{(0.0269)}}} & \thead{0.6004 \tiny{(0.0193)}}     & \thead{0.5494  \tiny{(0.0502)}} & \thead{0.5885  \tiny{(0.0365)}} & \thead{0.6149  \tiny{(0.0263)}} \\ 
   
    \bottomrule
  \end{tabular}
  }
\end{table}

\begin{figure*}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{./picture/exp.pdf}
	\caption{Comparison with different GNN backbone on 50-shots setting. Three picture correspond to the performance on three different datasets respectively. }
	\label{fig:exp}
\end{figure*}



\subsection{In-depth analysis of G-Prompt}
To validate the rationality of G-Prompt, we conduct ablation study to compare the performance of G-Prompt and its variants. These variants include removing the gate mechanism in graph-adapter (denoted as ``w/o gate''), keeping only self-loops while removing the input graph (denoted as ``w/o graph''), and not training graph-adapter by self-supervised learning (denoted as ``w/o SSL''). The experiment results show that all variants perform worse than G-Prompt. Specifically, removing the Graph-Adapter training process leads to  \textit{avg.} 2.8\% decrease in performance, which demonstrates the effectiveness of training graph-adapter through the fill- mask task. After removing the graph input, the performance of G-Prompt decreases by \textit{avg.} 3.8\%, which further confirms that the improvement of G-Prompt stems from the graph adapter's ability to assist language models in comprehending graph structures compared to using language model prompts directly. Moreover, removing the gate mechanism results in a \textit{avg.} 1.8\% decrease in performance, indicating that the design of the graph-adapter structure is reasonable.




















% saved in 5:03

% \begin{table}[t!]
% \caption{This is the title}
% \label{table:table}
% \renewcommand{\arraystretch}{0.85}
% \centering
% \resizebox{0.9\textwidth}{!}{
% \begin{tabular}{c|ccc|ccc|ccc}
% \toprule
% {\textbf{Dataset}} & \multicolumn{3}{c|}{\textbf{Arxiv}} & \multicolumn{3}{c|}{\textbf{Ins}} & \multicolumn{3}{c}{\textbf{Reddit}} \\
% %\cmidrule(r){1-5}
% \# shots per class & 10 & 50 &100 & 10 & 50 &100 & 10 & 50 &100 \\
% \midrule


% \renewcommand{\arraystretch}{0.85}
% \thead{ OGB-Feature} & \thead{0.4576 \\ \tiny{$\pm$0.0324}} & \thead{0.5495 \\ \tiny{$\pm$0.0171}}&\thead{ 0.5875 \\ \tiny{$\pm$0.0146}} & -&-&-&-&-&-\\

    
% \thead{ RoBERTa*+GAE} & \thead{0.5016 \\ \tiny{$\pm$0.0510} }& \thead{ 0.5608 \\ \tiny{$\pm$0.0101}} & \thead{0.5810 \\ \tiny{$\pm$0.0125} } &\thead{ 0.5258 \\ \tiny{$\pm$0.0635}} & \thead{0.5818 \\ \tiny{$\pm$0.0101} }& \thead{0.5821 \\\tiny{$\pm$0.0058}} & \thead{ 0.5653 \\ \tiny{$\pm$0.0256} }& \thead{0.6019 \\\tiny{$\pm$0.0174} }& \thead{0.6154 \\ \tiny{$\pm$0.0128}}\\

    
% \thead{ RoBERTa*+GAE\\+prompt} &\thead{0.5189 \\ \tiny{$\pm$0.0333} }& \thead{ 0.5801 \\ \tiny{$\pm$0.0102}} & \thead{0.6063 \\ \tiny{$\pm$0.0109} } &\thead{ 0.5418 \\ \tiny{$\pm$0.0298}} & \thead{0.5705 \\ \tiny{$\pm$0.0233} }& \thead{0.5867 \\\tiny{$\pm$0.0100}} & \thead{ 0.5619 \\ \tiny{$\pm$0.0425} }& \thead{0.5968 \\\tiny{$\pm$0.0237} }& \thead{0.6173 \\ \tiny{$\pm$0.016}}\\
    
%     \thead{ GIANT} & \thead{0.5050 \\ \tiny{$\pm$0.0308} }& \thead{ 0.5798 \\ \tiny{$\pm$0.0119}} & \thead{0.6081 \\ \tiny{$\pm$0.0109} } &\thead{ 0.5185 \\ \tiny{$\pm$0.0323}} & \thead{0.5601 \\ \tiny{$\pm$0.0304} }& \thead{0.5752 \\\tiny{$\pm$0.0251}} & \thead{ 0.5618 \\ \tiny{$\pm$0.0431} }& \thead{0.5954 \\\tiny{$\pm$0.0131} }& \thead{0.6130 \\ \tiny{$\pm$0.0117}}\\

     
%     \thead{ GIANT \\+ prompt} & \thead{0.5140 \\ \tiny{$\pm$0.0320} }& \thead{ 0.5809 \\ \tiny{$\pm$0.0223}} & \thead{0.6126 \\ \tiny{$\pm$0.0159} } &\thead{ 0.5239 \\ \tiny{$\pm$0.0309}} & \thead{0.5721 \\ \tiny{$\pm$0.0361} }& \thead{0.5949 \\\tiny{$\pm$0.0089}} & \thead{ 0.5661 \\ \tiny{$\pm$0.0459} }& \thead{0.5968 \\\tiny{$\pm$0.0096} }& \thead{0.6145 \\ \tiny{$\pm$0.0105}}\\
%     \hline
%     RoBERTa-cls & \thead{0.4697 \\ \tiny{$\pm$0.0577} }& \thead{ 0.5414 \\ \tiny{$\pm$0.0400}} & \thead{0.5869 \\ \tiny{$\pm$0.0300} } &\thead{ 0.5165 \\ \tiny{$\pm$0.0217}} & \thead{0.5385 \\ \tiny{$\pm$0.0344} }& \thead{0.5690 \\\tiny{$\pm$0.0253}} & \thead{ 0.4965 \\ \tiny{$\pm$0.0373} }& \thead{0.5236 \\\tiny{$\pm$0.0394} }& \thead{0.5754 \\ \tiny{$\pm$0.0348}}\\

  
%     \thead{ RoBERTa-Prompt\\-dense} & \thead{0.5117 \\ \tiny{$\pm$0.0398} }& \thead{ 0.5631 \\ \tiny{$\pm$0.0352}} & \thead{0.5865 \\ \tiny{$\pm$0.0296} } &\thead{ 0.5458 \\ \tiny{$\pm$0.0420}} & \thead{0.5796 \\ \tiny{$\pm$0.0276} }& \thead{0.6055 \\\tiny{$\pm$0.0122}} & \thead{ 0.5363 \\ \tiny{$\pm$0.0530} }& \thead{0.5648 \\\tiny{$\pm$0.0385} }& \thead{0.5998 \\ \tiny{$\pm$0.0383}}
%                    \\

                   
%     \thead{ RoBERTa-Prompt\\-vocabulary} & \thead{0.5201 \\ \tiny{$\pm$0.0284} }& \thead{ 0.5784 \\ \tiny{$\pm$0.0213}} & \thead{0.6085 \\ \tiny{$\pm$0.0203} } &\thead{ 0.5363 \\ \tiny{$\pm$0.0348}} & \thead{0.5757 \\ \tiny{$\pm$0.0225} }& \thead{0.5910 \\\tiny{$\pm$0.0229}} & \thead{ 0.5403 \\ \tiny{$\pm$0.0424} }& \thead{0.5761 \\\tiny{$\pm$0.0359} }& \thead{0.6082 \\ \tiny{$\pm$0.0192}}\\
%                \hline 
             
  
%       % \thead{G-Prompt \\ } & \thead{0.5232 \\ \scriptsize{$\pm$0.0348} }& \thead{ \underline{0.5909} \\ \underline{\scriptsize{$\pm$0.0159}}} & \thead{\textbf{0.6240$^*$} \\ \textbf{\scriptsize{$\pm$0.0156}} } &\thead{ \underline{0.5519} \\ \underline{\scriptsize{$\pm$0.0355}}} & \thead{\underline{0.5787} \\ \underline{\scriptsize{$\pm$0.0333}} }& \thead{\underline{0.6084} \\\underline{\scriptsize{$\pm$0.0127}}} & \thead{ \textbf{0.5794$^*$} \\ \textbf{\scriptsize{$\pm$0.0495}} }& \thead{\underline{0.6149} \\\underline{\scriptsize{$\pm$0.0270} }}& \thead{\underline{0.6427} \\ \underline{\scriptsize{$\pm$0.0185}}}\\
      
%       \thead{G-Prompt} & \thead{\underline{0.5248} \\ \underline{\tiny{$\pm$0.0382}} }& \thead{ \textbf{0.5927$^*$} \\ \textbf{\tiny{$\pm$0.0142}}} & \thead{\underline{0.6167} \\ \tiny{\underline{$\pm$0.0138}}}  &\thead{ \textbf{0.5576$^*$} \\ \textbf{\tiny{$\pm$0.0330}}} & \thead{\textbf{0.5917$^*$} \\ \textbf{\tiny{$\pm$0.0242}} }& \thead{\textbf{0.6090$^*$} \\\textbf{\tiny{$\pm$0.0135}}} & \thead{ \textbf{0.5728}$^*$ \\ \textbf{\tiny{$\pm$0.0491}$^*$} }& \thead{\textbf{0.6167$^*$}\\\textbf{\tiny{$\pm$0.0289}} }& \thead{\textbf{0.6472$^*$} \\\textbf{ \tiny{$\pm$0.0224}}}\\

%      \hline
     
%  \thead{G-Prompt \\ w/o gate} & \thead{\textbf{0.5291$^*$} \\ \textbf{\tiny{$\pm$0.0315}} }& \thead{ 0.5877 \\ \tiny{$\pm$0.0192}} & \thead{\textbf{0.6212$^*$} \\ \textbf{\tiny{$\pm$0.0190}} } &\thead{ \underline{0.5507} \\ \underline{\tiny{$\pm$0.0336}}} & \thead{0.5706 \\ \tiny{$\pm$0.0262} }& \thead{0.5942 \\\tiny{$\pm$0.0178}} & \thead{ 0.5501 \\ \tiny{$\pm$0.0604} }& \thead{\underline{0.5926} \\\underline{\tiny{$\pm$0.0385}} }& \thead{\underline{0.6361} \\ \underline{\tiny{$\pm$0.0268}}}\\

     

   
     
%     \thead{G-Prompt \\ w/o graph} & \thead{0.5226 \\ \tiny{$\pm$0.0322}} & \thead{\underline{0.5880} \\ \underline{\tiny{$\pm$0.0168}}} & \thead{0.6059 \\ \tiny{$\pm$0.0101}} \
%      & \thead{0.5234 \\ \tiny{$\pm$0.0236}} & \thead{0.5657 \\ \tiny{$\pm$0.0377}} & \thead{0.5914 \\ \tiny{$\pm$0.0199}}     & \thead{\underline{0.5536} \\ \underline{\tiny{$\pm$0.0438}}} & \thead{0.5683 \\ \tiny{$\pm$0.0390}} & \thead{0.6054 \\ \tiny{$\pm$0.0263}} \\ 

    
%     \thead{G-Prompt \\ w/o SSL} & \thead{0.5210 \\ \tiny{$\pm$0.0372}} & \thead{0.5793 \\ \tiny{$\pm$0.0168}} & \thead{0.6092 \\ \tiny{$\pm$0.0168}} \
%      & \thead{0.5378 \\ \tiny{$\pm$0.0419}} & \thead{\underline{0.5801} \\ \underline{\tiny{$\pm$0.0269}}} & \thead{\underline{0.6004} \\ \underline{\tiny{$\pm$0.0193}}}     & \thead{0.5494 \\ \tiny{$\pm$0.0502}} & \thead{0.5885 \\ \tiny{$\pm$0.0365}} & \thead{0.6149 \\ \tiny{$\pm$0.0263}} \\ 
   
%     \bottomrule
%   \end{tabular}
%   }
% \end{table}


% \begin{figure*}[ht]
% 	\centering
% 	\includegraphics[width=0.7\textwidth]{./picture/exp.pdf}
% 	\caption{\hxw{Comparsion}\zzs{Comparison} with different GNN backbone on 50-shots setting}
% 	\label{fig:exp}
% \end{figure*}








% \begin{table}
%    % \fontsize{5}{12}\selectfont
%   \caption{This is the title}
%   \label{table:table}
%   \centering
%   \resizebox{\textwidth}{!}{
%     \begin{tabular}{c|ccc|ccc|ccc}
%       \toprule
%        {\textbf{Dataset}} & \multicolumn{3}{c|}{\textbf{Arxiv}}   & \multicolumn{3}{c|}{\textbf{Insdata}}      & \multicolumn{3}{c}{\textbf{Reddit}}              \\
%       %\cmidrule(r){1-5}
%                  # Shot per class & 10  & 50 &100    & 10  & 50 &100  & 10  & 50 &100   \\
%       \midrule
%       OGB-Feature & 0.4576  \scriptsize{$\pm$0.0.032} & 0.5495 \scriptsize{$\pm$0.0171}& 0.5875 \scriptsize{$\pm$0.0146} & -&-&-&-&-&-\\
%        RoBERTa*+GAE& 0.5016 \scriptsize{$\pm$0.0510} & 0.5608 \scriptsize{$\pm$0.0101} & 0.5810 \scriptsize{$\pm$0.0125} \
%       & 0.5037 \scriptsize{$\pm$0.0684} & 0.5553 \scriptsize{$\pm$0.0472} & 0.5765 \scriptsize{$\pm$0.0282} &\
%       0.5709 \scriptsize{$\pm$0.0282} & 0.6020 \scriptsize{$\pm$0.0141}& 0.6140 \scriptsize{$\pm$0.0130}\\
%       RoBERTa*+GAE\_prompt\\
%       GIANT & 0.5050 \scriptsize{$\pm$0.0308} & 0.5798\scriptsize{$\pm$0.0119} & 0.6081 \scriptsize{$\pm$0.0109} 
%         & 0.5224 \scriptsize{$\pm$0.0308} & 0.5645 \scriptsize{$\pm$0.0284} & 0.5868 \scriptsize{$\pm$0.0242} 
%         & 0.5639 \scriptsize{$\pm$0.0387} & 0.5948 \scriptsize{$\pm$0.0131} & 0.6114 \scriptsize{$\pm$0.0107} 
%        \\
%       GIANT\_Prompt\\ \hline
%       RoBERTa-cls & 0.4697 \scriptsize{$\pm$0.0577} & 0.5414 \scriptsize{$\pm$0.0400} & 0.5869 \scriptsize{$\pm$0.0300} 
%               & 0.5063 \scriptsize{$\pm$0.0163} & 0.5177 \scriptsize{$\pm$0.0279} & 0.5580 \scriptsize{$\pm$0.0375} 
%               & 0.5018 \scriptsize{$\pm$0.0410} & 0.5166 \scriptsize{$\pm$0.0361} & 0.5716 \scriptsize{$\pm$0.0255} 
%     \\
%       RoBERTa-prompt-emb & 0.5117 \scriptsize{$\pm$0.0398} & 0.5631 \scriptsize{$\pm$0.0352} & 0.5865 \scriptsize{$\pm$0.0296} \
%                      & 0.5180 \scriptsize{$\pm$0.0189} & 0.5622 \scriptsize{$\pm$0.0507} & 0.5831 \scriptsize{$\pm$0.0254} \
%                      & 0.5341 \scriptsize{$\pm$0.0493} & 0.5634 \scriptsize{$\pm$0.0398} & 0.6104 \scriptsize{$\pm$0.0274} \
%                      \\
%       RoBERTa-vob & \multirow{2}{*}{0.5201} \raisebox{-0.5ex}{\scriptsize{$\pm$0.0284}} 
%                    & \multirow{2}{*}{0.5784} \raisebox{-0.5ex}{\scriptsize{$\pm$0.0213}} 
%                    & \multirow{2}{*}{0.6085} \raisebox{-0.5ex}{\scriptsize{$\pm$0.0203}} 
%                    & \multirow{2}{*}{0.5290} \raisebox{-0.5ex}{\scriptsize{$\pm$0.0271}} 
%                    & \multirow{2}{*}{0.5618} \raisebox{-0.5ex}{\scriptsize{$\pm$0.0508}} 
%                    & \multirow{2}{*}{0.5825} \raisebox{-0.5ex}{\scriptsize{$\pm$0.0180}} 
%                    & \multirow{2}{*}{0.5287} \raisebox{-0.5ex}{\scriptsize{$\pm$0.0514}} 
%                    & \multirow{2}{*}{0.5613} \raisebox{-0.5ex}{\scriptsize{$\pm$0.0348}} 
%                    & \multirow{2}{*}{0.5935} \raisebox{-0.5ex}{\scriptsize{$\pm$0.0452}} \\
%       & & & & & & & & & \\ % 添加一个空行，使得第六行的内容下移
%       \hline
%       Ours & 0.5232 \scriptsize{$\pm$0.0348} & 0.5909 \scriptsize{$\pm$0.0159} & 0.6240 \scriptsize{$\pm$0.0156} \
%        & 0.5288 \scriptsize{$\pm$0.0335} & 0.5809 \scriptsize{$\pm$0.0487} & 0.6010 \scriptsize{$\pm$0.0123} \
%        & 0.5686 \scriptsize{$\pm$0.0620} & 0.6088 \scriptsize{$\pm$0.0438} & 0.6504 \scriptsize{$\pm$0.0162} \\
%       \bottomrule
%     \end{tabular}
%   }
% \end{table}


\subsection{Zero-shot node classification and interpretability}

The node features generated through GPrompt represent the probability of each possible token for nodes given task-related prompts, where each dimension corresponds to a specific token. 
This probability generation incorporates prior knowledge from PLMs, graph information, and nodes' context.
Two natural questions arise: \textbf{How much knowledge is contained within this word probability? Whether the node feature can help us interpret the downstream task?}
Therefore, we further conduct zero-shot node classification experiments  based on the generated node representation. Meanwhile, we conduct a case study on Instagram.


\textbf{Zero-shot node classification.} Firstly, we select different sets of candidate tokens for each node class. Then, for each class, we sum up the probability of each tokes in the correspondding set as the final prediction results. We employ the AUC-ROC as the evaluation metric to assess the performance of node classification.
For simplicity, ArXiv dataset only selects two categories, ``Artificial Intelligence'' and ``Linguistics and Language''. The other two datasets remain unchanged. 
We select completely random  (denoted as ``Rand.''), bag-of-words (denoted as ``BOW''), RoBERTa-base (denoted as ``LM-B''), and RoBERTa-large  (denoted as ``LM-L'') as baselines, using the same prompts as G-Prompt for PLMs. 
We provide experiment results of G-Prompt based on RoBERTa-base (Ours-B) and RoBERTa-large (Ours-L).

According to the results shown in Table 3. 
(1) The bag-of-words method has almost no predictive ability. 
(2) The PLM through prompts has predictive ability on different tasks (improvement compared to BOW by \textit{avg.} 13\%). 
But there is a performance difference between base and large even with the same prompt due to the sensitivity of language models to prompts \cite{lu2021fantastically}.
(3) Compared to a language model, G-Prompt shows significant performance improvement. 
Specifically, G-Prompt-base improved \textit{avg.} 2.7\% compared to the language model. 
However, it should be noted that the basic predictive ability of the language model and G-Prompt are correlated. 
Specifically, the correlation coefficient between the results of GPrompt-L and LM-L is 0.64, while the correlation coefficient with LM-B is  0.84. 
(4) Moreover, selecting more candidate words through prior knowledge can effectively help G-Prompt improve its zero-shot capability, with an average improvement of \textit{avg.} 4.8\% for the base and \textit{avg.} 5.3\% for the large. However, there is no significant improvement for language models and bag-of-words. Surprisingly, by adding a small number of candidate words, G-Prompt's zero-shot performance is already close to or even sometimes surpasses  supervised training with 100 shots. This result indicates that combining language models and graphs for zero-shot learning on TAG is feasible.

% In order to evaluate the ability of our model in a zero-shot setting, we choose some words highly related to the task based on prior knowledge and use the prediction of the words to get the results. 
% We generate the distribution of each word in the vocabulary of the language model with RoBERTa-large and RoBERTa-small separately. For each sample, the distribution of positive words and negative words is added distinctly and simply compared to their values to determine the label of the sample.
% For Axiv, two categories are selected to make the results compared more clear. 

% We compare our methods with some baselines. Rand. the method gives the results of the prediction randomly. By counting the frequency of word occurrences in the sample, the word bag method predicts the labels according to the frequency of given words. The feature generated by only RoBERTa-large or RoBERTa-small is used by the same way as our model.

% As shown in Table 3, our models have competitive results, showing the importance of text attributes in a TAG compared with other models, showing our method utilizes the text feature better and has sufficient interpretability. By comparing the results with the performance of supervised model on 100 shots, our models achieve comparable performance with supervised baselines, which demonstrate the advantages of our model in zero-shot tasks.

% To show the excellent interpretability of our model further, the top 10 tokens that are most related to the result of prediction and their scores are collected for the task to detect the commercial users in ins. As shown in Table 4, the result of our model is more interpretable than RoBERTa-large. For example,  \textit{premium} represents something given free or at a reduced price with the purchase of a product or service\cite{} and \textit{niche} represents a specific interest or topic that a user's content focuses on. Both of them are highly related to commercial users and assist us to understand the model more deeply.
\textbf{Interpretability.}
The task on Instagram is to determine whether a node is a commercial user. We use the probability corresponding to each token as the prediction value, calculate its corresponding ROC of prediction performance, and then display the top 7 tokens with the highest scores. For comparison, we also show the scores of tokens corresponding to RoBERTa-Large under the same prompt. Overall, the top 7 tokens given by our model have considerably higher ROC scores than RoBERTa-Large resulting in \textit{avg.} 7.0\% improvement. Additionally, our results are intuitive and can even help explain the task, for example, ``premium.'' Based on this result, we search and find that there are ``premium creator subscriptions'' on Instagram, which means ``Users can set their own prices and earn extra cash each month,''\footnote{\url{https://www.pcmag.com/news/instagram-introduces-premium-creator-subscriptions}} and this information is indeed related to commercial activity. Similarly, ``niche'' is also a word related to Instagram business behavior.

\renewcommand{\multirowsetup}{\centering}
\begin{table}[t!]
   % \fontsize{5}{12}\selectfont
  \caption{The performance of different models in zero-shot learning. For each dataset, two categories of words corresponding to the two labels are selected according to the piror knowledge noted as Pos.vocab and Neg.vocab. AUC is used as evaluation metric (mean ± std\%, the best results are bolded and the runner-ups are underlined).}
  \label{table:table_unsurperviesd}
  
  \centering
  \resizebox{0.8\textwidth}{!}{
      \begin{tabular}{c|c|c|cccc|cc|c}
            \toprule
             {\textbf{Dataset}} & 
             {\textbf{Pos. vocab}} &
             {\textbf{Neg. vocab}} &
             {\textbf{Rand.}} &
             {\textbf{BOW}} &
             {\textbf{LM-B}} &
             {\textbf{LM-L}} &
             {\textbf{Ours-B}} &
             {\textbf{Ours-L}} &
             {\textbf{100 shot.}}
             \\
            \midrule
            \midrule
            \multirow{4}{*}{\textbf{Arxiv}} & 
            \thead{\{\textit{intellectual}\}} & 
            \thead{ \{\textit{language}\}}&
           \thead{ 0.5021\\ \scriptsize{(0.0124)}} & 
           \thead{ 0.4994\\ \scriptsize{(0.0000)}} & 
           \thead{ 0.5955\\ \scriptsize{(0.0000)}} &
           \thead{ \underline{0.6747}\\ \underline{\scriptsize{(0.0000)}}} &
           \thead{ 0.5840\\ \scriptsize{(0.0000)}} &
           \thead{ \textbf{0.6765$^*$}\\ \scriptsize{\textbf{(0.0000)}}} &
           \multirow{4}{*}{\thead{0.9040 \\ \scriptsize{(0.0253)}}}\\
           
          \cline{2-9} & 
          \thead{\{\textit{intellectual}, \\ \textit{decision},\\\textit{logic}, ...\}}& 
           \thead{ \{\textit{language}, \\\textit{translation},\\ \textit{speech}, ...\}}&
           \thead{ 0.4988\\ \scriptsize{(0.0139)}} & 
           \thead{ 0.5474\\ \scriptsize{(0.0000)}} &
           \thead{ \underline{0.6284}\\ \underline{\scriptsize{(0.0000)}}}&
           \thead{ 0.6075\\ \scriptsize{(0.0000)}} &
           \thead{ 0.6006\\ \scriptsize{(0.0000)}} &
           \thead{ \textbf{0.7064$^*$}\\ \scriptsize{\textbf{(0.0000)}}} &
           \\
         \hline
         \hline
        
        
        
        
         
            \multirow{4}{*}{\textbf{Instagram}}& 
            \thead{\{\textit{commercial}\}} & 
            \thead{\{\textit{normal}\}}&
           \thead{ 0.5004 \\ \scriptsize{(0.0151)}} & 
           \thead{ 0.5001 \\ \scriptsize{(0.0007)}}&
           \thead{ \textbf{0.5509$^*$} \\ \scriptsize{\textbf{(0.0163)}}}&
           \thead{ 0.5365 \\ \scriptsize{(0.0054)}}&
           \thead{\underline{ 0.5403} \\ \scriptsize{\underline{(0.0078)}}}&
           \thead{ 0.5382 \\ \scriptsize{(0.0095)}}&
        
           \multirow{4}{*}{\thead{0.5690 \\ \scriptsize{(0.0253)}}}\\
           
             \cline{2-9}&
            \thead{\{\textit{commercial},\\ \textit{sponsored}, \\ \textit{brand}, ...\} }& 
            \thead{\{\textit{normal}, \\ \textit{personality},\\ \textit{private}, ...\}}& 
            \thead{ 0.5007 \\ \scriptsize{(0.0131)} } &
            \thead{ 0.5022 \\ \scriptsize{(0.0008)}} & 
            \thead{ 0.5586 \\ \scriptsize{(0.0117)}} & 
            \thead{ 0.5577 \\\scriptsize{(0.0068)}} & 
            \thead{ \textbf{0.5995$^*$} \\ \scriptsize{\textbf{(0.0074)}} }& 
            \thead{ \underline{0.5957} \\\scriptsize{\underline{(0.0081)}} }& \\
            \hline
            \hline
        

            \multirow{4}{*}{\textbf{Reddit}}& 
            \thead{\{\textit{pretty}\}} 
            & \thead{\{\textit{simple}\}}&
           \thead{ 0.5034 \\ \scriptsize{(0.0073)}} &
           \thead{ 0.5053 \\ \scriptsize{(0.0019)}} &
           \thead{ 0.5608 \\ \scriptsize{(0.0050)}} &
           \thead{ 0.5352 \\ \scriptsize{(0.0027)}} &
           \thead{ \underline{0.5630} \\ \underline{\scriptsize{(0.0082)}}} &
           \thead{ \textbf{0.5673$^*$} \\ \scriptsize{\textbf{(0.0070)}}} &
           
           \multirow{4}{*}{\thead{0.5754  \\ \scriptsize{(0.0348)}}}\\
           \cline{2-9} &
            \thead{\{\textit{pretty},\\\textit{hilarious},\\\textit{funny}, ...\}}& 
            \thead{\{\textit{simple},\\ \textit{anonymous},\\ \textit{standard}, ...\}} &
            \thead{0.4990 \\ \scriptsize{(0.0042)} } &
            \thead{ 0.5034 \\ \scriptsize{(0.0017)}} & 
            \thead{0.5604 \\ \scriptsize{(0.0081)} }& 
            \thead{0.5587 \\\scriptsize{(0.0052)}} & 
            \thead{ \underline{0.5674} \\ \scriptsize{\underline{(0.0058)} }}& 
            \thead{\textbf{0.5742$^*$} \\\scriptsize{\textbf{(0.0066)}} }& \\
            \bottomrule
        \end{tabular}}
\end{table}

\begin{table}[t!]
  \caption{Top 7 Tokens related to predicting commercial users on Instagram}
    \label{Table:overview}
  \centering
  \resizebox{0.4\textwidth}{!}{
      \begin{tabular}{cc|cc}
        \toprule
         \multicolumn{2}{c|}{\textbf{RoBERTa-large}}   & \multicolumn{2}{c}{\textbf{G-Prompt}}          \\
         \textbf{Top 7 tokens}&\textbf{ROC}&\textbf{Top 7 tokens}&\textbf{ROC}\\
         \hline
            \textit{{critical}}& 0.546& \textit{{special}}& 0.592\\
        \textit{{convenient}}& 0.542 &\textit{{convenient}}& 0.579\\
        \textit{{terrific}}&0.542&\textit{{premium}}& 0.579\\
        \textit{{banner}}& 0.542 &\textit{{unique}}&  0.577 \\
        \textit{{gateway}}& 0.539 &\textit{{great}}&  0.575 \\
        \textit{{compelling}}& 0.539 &\textit{{pioneer}}& 0.575\\
        \textit{{neat}}& 0.538 &\textit{{niche}}&  0.575 \\
        %\cmidrule(r){1-5}
        \bottomrule
      \end{tabular}}
\end{table}


