\section{Conclusion}
This paper proposes G-Prompt to fuse PLMs and Graphs for extracting task-specific and graph-aware node representation in TAGs. G-Prompt have two-stage: (1) self-supervised train a graph adapter to make PLMs graph-aware based TAGs, and (2) employing prompts with the trained graph adapter to extract node representation from TAGs.
Experiments with different shot settings using three datasets demonstrate that the proposed model can effectively capture both text and graph information, resulting in improved performance for few-shot learning.
In zero-shot learning, our model achieves comparable performance with supervised baselines and has huge potential for future work.
Furthermore, our model provides useful interpretations, which is essential for understanding the tasks and TAGs.