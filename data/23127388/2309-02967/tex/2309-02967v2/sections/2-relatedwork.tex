\section{Related Work}

In this section, we review research on visualization understanding, visualization enhancement and data video generation.
\subsection{Visualization Understanding}
The proliferation of visualizations gives rise to research efforts to understand existing images automatically~\cite{davila2021charta}.
Given visualization images, researchers seek to understand their content (e.g., chart type, data, and visual encodings).
Based on the image input, prior works can be mainly categorized into two classes: raster image and vector image.

Researchers have explored the interpretation of raster images from different perspectives~\cite{gao2012view, poco2017reverseengineering}.
For instance, Savva et al.~\cite{savva2011revision} proposed ReVision, which identified chart types and extracted data from bitmap charts.
Later Davila et al.~\cite{davila2021charta} conducted a survey that covered the topic of automated data extraction from chart images.
Despite the support of extracting various information from chart images, raster images are hard to reuse or add extra graphic elements onto the image~\cite{masson2023chartdetective}.
% SVG
Harper and Agrawala~\cite{harper2014deconstructing, harper2017converting} focused on vector images and used D3 chart~\cite{bostock2011DataDriven} as the input to extract the complete chart structure.
With the embedded information, the charts can be utilized in multiple scenes, such as restyle~\cite{harper2014deconstructing}, template extracting~\cite{harper2017converting}, and style searching~\cite{hoque2019searchinga}.
Kim et al.~\cite{kim2020answering} focused on Vega-Lite charts~\cite{satyanarayanvegalite} and extracted data and visual encodings in two stages.
Recently, Masson et al.~\cite{masson2023chartdetective} proposed an interactive method to extract data from vector charts.

Our approach also takes vector charts as the input since we need to motion the image.
We use charts in SVG format with structural information~\cite{li2022structure}.
Moreover, the structures of charts generated by different tools are distinct (e.g., D3, Vega-lite, and Adobe Illustrator).
Compared with the methods that targeted a specific SVG type, our model's structure is not influenced by the format of SVG files. 
Specially, we analyze the structure information for online SVGs automatically by GNN techniques, including the data and visual encodings.


\subsection{Visualization Enhancement}
Visualization enhancement has attracted researchers' interest in recent years with the evolving techniques of visual understanding~\cite{kai2023comantics}, which may assist users in understanding the visualization quickly and effectively.
The methods can be mainly categorized into three categories, question-answering, annotation, and caption.

Question answering refers to generating answers given a question. 
Some studies include DQVA~\cite{kafle2018dvqaa}, FigureQA~\cite{kahou2018figureqa}, PlotQA~\cite{methani2020plotqa} contributed datasets and models for different plots.
Further, researchers explored new methods (e.g., LEAF-QA~\cite{chaudhry2020leafqa}, FigureNet~\cite{reddy2019figurenet}) to achieve higher accuracy in question-answering tasks.
Compared with treating the input chart image using computer vision techniques, Kim et al.~\cite{kim2020answering} focused on Vega-lite charts and extracted the chart structure to answer natural language questions.

Annotation, as the extra graphical or textual elements~\cite{munzner2014visualization}, plays a vital role in conveying information in data-driven storytelling~\cite{ren2017chartaccent} and attracting users' attention to specific parts of the visualization~\cite{bongshinlee2013sketchstory}.
Kong and Agrawala~\cite{kong2012graphicala} presented an automatic system to aid chart reading by generating desired overlays.
Bryan et al.~\cite{bryan2017temporal} proposed Temporal Summary Images to assist visualization analysis via interactive annotation by inputting images and raw data.
Lai et al.~\cite{lai2020automatic} adopted textual descriptions and images as the input.
They introduced an automatic pipeline for annotating visualization.
Unlike the raster images in the above work, Lu et al.~\cite{minlu2017interaction} focused on web-based visualizations and developed a system to augment them via a palette of interactions.
Ren et al.~\cite{ren2017chartaccent} characterized a design space of annotation and implemented ChartAccent, which enables users to easily enhance SVG-based charts by a series of annotation interactions.

The caption provides a summary for a visualization.
% early work
Mittal et al.~\cite{mittal1998describing} presented a system, which uses a text planner to select the caption content and structure.
% other 
Recently, researchers utilized template-based descriptions to depict charts in certain genres of narrative visualization~\cite{shi2021calliope}, such as slideshows~\cite{li2023notable}.
% model
With the development of computer vision and natural language processing techniques, researchers contributed plenty of models to generate accurate descriptions given rasterized charts~\cite{kantharaj2022charttotext, obeid2020charttotext}.
Liu et al.~\cite{liu2020autocaption} targeted vector images and proposed an approach including several models to generate captions automatically.

Our work aligns with the direction to augment the chart but goes beyond to revive the charts into Live Charts.


\subsection{Data Video Generation}
Plenty of research is dedicated to enhancing data visualization through creating data videos~\cite{amini2015understanding}. 
Many studies focus on integrating animations and developing systems to generate animations from data~\cite{amini2017authoring, shi2021autoclips, shin2022roslingifier}. 
For example, DataClips~\cite{amini2017authoring} allows non-experts to generate data videos by inputting data. 
Through a series of interactions, users can select and integrate data-driven clips from the given library and form a video.
DataParticles~\cite{cao2023dataparticles} allows creators to author animated unit visualization in data stories.
AutoClips~\cite{shi2021autoclips} moves forward to save human effort by automatically crafting data videos from a sequence of data facts.
However, the above work cannot revive static charts with image input.
There are alternative approaches that begin with specific image inputs.
For instance, Data Animator~\cite{thompson2021data} chooses the Data Illustrator~\cite{liu2018data} file format as the input, which includes detailed data and visual encoding information and enables authors to generate animated data graphics and transitions without programming.
Based on Canis~\cite{ge2020canis}, Ge et al.~\cite{ge2021cast} designed CAST, an interactive authoring tool to create data videos by inputting data-enriched SVGs.
However, these methods have specific input requirements and cannot process SVGs without data.

Though these tools assist users in generating animations, much effort is still required to transform static charts into Live Charts. 
Focused on infographics, Infomotion~\cite{wang2021animated} allows users to automatically generate animated presentations from static infographics.
However, it does not assist basic charts. Moreover, current studies tend to neglect the importance of audio narration, which is a crucial aspect of creating a comprehensive data video. 
As a result, users must still use additional tools to record audio narration and synchronize it with animation. 
In our research, we propose methods for automatically deriving Live Charts from static ones and consider both the animation and audio narration simultaneously in the process.