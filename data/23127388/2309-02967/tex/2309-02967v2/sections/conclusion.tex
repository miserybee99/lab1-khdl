\section{Conclusion}
In this paper, we have introduced Live Charts as a new format of data presentation that enhances traditional static charts by providing rich animations and audio narration. 
To automate the creation of Live Charts, we decompose complex information from static charts by adopting computer vision techniques and large natural language models. 
Our process first involves extracting data and visual encodings from the chart image, then generating data insights based on this information. We then create narrations and design animations, ultimately combining them to form a Live Chart. 
We conducted various assessments to evaluate the effectiveness of Live Charts and our auto-reviving process, including use cases, chart understanding performance test, a user study, and expert interviews.
The evaluation results demonstrate that Live Charts provide a multi-sensory and engaging experience, with animations and narration significantly contributing to data comprehension. 
Leveraging GPT-4's multimodal input and enhanced performance compared to GPT-3, future research can delve into advanced techniques for automating chart comprehension through LLM and enriching presentations with more vivid narration and animation.