@inproceedings{tpu,
author = {Jouppi, Norman P. and others},
title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
year = {2017},
booktitle = {Int. Symp. on Comp. Arch. (ISCA)},
pages = {1–12},
}

 @inproceedings{convnext,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11976--11986},
  year={2022}
}

@INPROCEEDINGS{adaptivfloat,
author={Tambe, Thierry and Yang, En-Yu and Wan, Zishen and Deng, Yuntian and Janapa Reddi, Vijay and Rush, Alexander and Brooks, David and Wei, Gu-Yeon},
  booktitle={Design Automation Conference (DAC)}, 
  title={Algorithm-Hardware Co-Design of Adaptive Floating-Point Encodings for Resilient Deep Learning Inference}, 
  year={2020},
  pages={1-6},
}

@INPROCEEDINGS{fused-arm,
  author={Lutz, David R.},
  booktitle={IEEE Symp. on Computer Arithmetic}, 
  title={Fused Multiply-Add Microarchitecture Comprising Separate Early-Normalizing Multiply and Add Pipelines}, 
  year={2011},
  pages={123-128},
}


@online{tensorfloat,
author = {M. Andersch and others}, 
title = {{NVIDIA Hopper architecture}},
year = 2022,
url = {https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth},
}

@online{bfloat-def,
 author = {Google},
 title ={The bfloat16 numerical format},
 year = 2022,
 url = {https://cloud.google.com/tpu/docs/bfloat16},
 urldate = {July 2022},
 }

@inproceedings{meissa,
  title={Meissa: Multiplying matrices efficiently in a scalable systolic architecture},
  author={Asgari, Bahar and Hadidi, Ramyad and Kim, Hyesoon},
  booktitle={IEEE Int. Conf. on Computer Design (ICCD)},
  pages={130--137},
  year={2020},
}

@inproceedings{scalesim,
  author={Samajdar, Ananda and others},
  booktitle={IEEE Int. Symp. on Perf. Analysis of Systems and Software (ISPASS)}, 
  title={A Systematic Methodology for Characterizing Scalability of {DNN} Accelerators using SCALE-Sim}, 
  year={2020},
  pages={58-68},
}

@inproceedings{factored-sa,
  author={Ullah, Inayat and Inayat, Kashif and Yang, Joon-Sung and Chung, Jaeyong},
  booktitle={Design Automation Conf. (DAC)}, 
  title={Factored Radix-8 Systolic Array for Tensor Processing}, 
  year={2020},
}

@article{why-systolic,
  author={H. T. Kung},
  journal={Computer}, 
  title={Why systolic architectures?}, 
  year={1982},
  volume={15},
  number={1},
  pages={37-46},
}


@article{hetero-sa,
author = {Xu, Rui and others},
title = {Configurable Multi-Directional Systolic Array Architecture for Convolutional Neural Networks},
year = {2021},
volume = {18},
number = {4},
journal = {ACM TACO},
month = {July},
articleno = {42},
numpages = {24},
}

@article{eyriss2,
  author={Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel and Sze, Vivienne},
  journal={IEEE JETCAS}, 
  title={Eyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices}, 
  year={2019},
  volume={9},
  number={2},
  pages={292-308},
}

@inproceedings{dataflow-mirroring,
  title={Dataflow mirroring: Architectural support for highly efficient fine-grained spatial multitasking on systolic-array npus},
  author={Lee, Jounghoo and Choi, Jinwoo and Kim, Jaeyeon and Lee, Jinho and Kim, Youngsok},
  booktitle={Design Automation Conference (DAC)},
  pages={247--252},
  year={2021},
  organization={IEEE}
}


@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and others},
  booktitle={IEEE CVPR},
  pages={770--778},
  year={2016}
}

@article{mobilenet,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and others},
  journal={arXiv:1704.04861},
  year={2017}
}


@inproceedings{ten-lessons,
  title={Ten lessons from three generations shaped google’s tpuv4i: Industrial product},
  author={Jouppi, Norman P and Yoon, Doe Hyun and Ashcraft, Matthew and Gottscho, Mark and Jablin, Thomas B and Kurian, George and Laudon, James and Li, Sheng and Ma, Peter and Ma, Xiaoyu and others},
  booktitle={Intern. Symp. on Computer Architecture (ISCA)},
  pages={1--14},
  year={2021},
  organization={IEEE}
}

@misc{tensorflow,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and others},
  year={2015},
}

@article{imagenet,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@article{hw-for-cnn,
  title={Efficient processing of deep neural networks: A tutorial and survey},
  author={Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S},
  journal={Proceedings of the IEEE},
  volume={105},
  number={12},
  pages={2295--2329},
  year={2017},
}




@article{app-specific-fp,
  title={Application-specific arithmetic in high-level synthesis tools},
  author={Uguen, Yohann and Dinechin, Florent De and Lezaud, Victor and Derrien, Steven},
  journal={ACM Trans. on Architecture and Code Optimization (TACO)},
  volume={17},
  number={1},
  pages={1--23},
  year={2020},
}

@article{four4-vector,
  title={A floating-point unit for 4D vector inner product with reduced latency},
  author={Kim, Donghyun and Kim, Lee-Sup},
  journal={IEEE Trans. on computers},
  volume={58},
  number={7},
  pages={890--901},
  year={2008},
}

@inproceedings{fused-swarz,
  title={Improved architectures for a floating-point fused dot product unit},
  author={Sohn, Jongwook and Swartzlander, Earl E},
  booktitle={IEEE Symp. on Comp. Arithmetic (ARITH)},
  pages={41--48},
  year={2013},
}

@inproceedings{fused-intel,
  title={Optimized fused floating-point many-term dot-product hardware for machine learning accelerators},
  author={Kaul, Himanshu and Anders, Mark and Mathew, Sanu and Kim, Seongjong and Krishnamurthy, Ram},
  booktitle={IEEE Symp. on Comp. Arithmetic (ARITH)},
  pages={84--87},
  year={2019},
}

@inproceedings{intel-nervana,
  title={{Intel Nervana Neural Network Processor-T (NPP-T) Fused Floating Point Many-Term Dot Product}},
  author={Hickmann, Brian and others},
  booktitle={IEEE Symp. on Comp. Arithmetic (ARITH)},
  pages={133--136},
  year={2020},
}


@article{bfloat,
  title={{BFloat16: The secret to high performance on Cloud TPUs}},
  author={Wang, Shibo and Kanwar, Pankaj},
  journal={Google Cloud Blog},
  volume={4},
  year={2019}
}

@article{quantization,
  title={A survey of quantization methods for efficient neural network inference},
  author={Gholami, Amir and others},
  journal={arXiv preprint arXiv:2103.13630},
  year={2021}
}


@INPROCEEDINGS{no-fma-chain,
  author={Hickmann, Brian and Bradford, Dennis},
  booktitle={IEEE Symp. on Comp. Arithmetic (ARITH)}, 
  title={Experimental Analysis of Matrix Multiplication Functional Units}, 
  year={2019},
  pages={116-119},}

@inproceedings{arrayflex,
  author={
  Peltekis, Christodoulos and
  Filippas, Dionysios  and Dimitrakopoulos, Giorgos and Nicopoulos, Chrysostomos and Pnevmatikatos, Dionisios},
  booktitle={Design Automation and Test in Europe (DATE)}, 
  title={{ArrayFlex: A Systolic Array Architecture with Configurable Transparent Pipelining}}, 
  year={2023},
}

@INPROCEEDINGS{aicas-fp,
  author={Li, Kai and Zhou, Junzhuo and Li, Boyu and Yang, Shuxing and Huang, Sixiao and Luo, Shaobo and Mao, Wei and Yu, Hao},
  booktitle={IEEE Intern. Conf. on Artificial Intelligence Circuits and Systems (AICAS)}, 
  title={A Vector Systolic Accelerator for Multi-Precision Floating-Point High-Performance Computing}, 
  year={2022},
  pages={226-229},
}


@article{AlexNet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
year = {2017},
volume = {60},
number = {6},
journal = {Commun. ACM},
pages = {84–90},
}




 @inproceedings{YOLO,
 author               = {J.~Redmon and S.~Divvala and R.~Girshick and A.~Farhadi},
 booktitle            = {{IEEE} Conf. on Computer Vision and Pattern Recognition ({CVPR})},
 title                = {{{You Only Look Once}: Unified, Real-Time Object Detection}},
 pages                ={779--788},
 year                 = {2016},
 }
 

 @article{NLP_CNN,
 author               = {T.~Young and D.~Hazarika and S.~Poria and E.~ Cambria},
 journal              = {IEEE Computational Intelligence Magazine},
 number               = {3},
 pages                = {55 -- 75},
 title                = {{Recent Trends in Deep Learning Based Natural Language Processing}},
 volume               = {13},
 year                 = {2018},
 }
 
 @article{spatial,
 author = {Paulius Micikevicius, NVIDIA},
 journal = {HotChips},
 title = {{Modern neural networks and their computational characteristics}},
 year = {2021},
 }

 
  @inproceedings{CNN-SLAM,
 author               = {K.~Tateno and F.~Tombari and I.~Laina and N.~Navab},
 booktitle            = {{IEEE} Conf. on Computer Vision and Pattern Recognition ({CVPR})},
 title                = {{{CNN-SLAM}: {Real-Time Dense Monocular {SLAM} with Learned Depth Prediction}}},
 pages                ={6243--6252},
 year                 = {2017},
 }






@INPROCEEDINGS{vector-drim,
  author={Patsidis, Kariofyllis and Nicopoulos, Chrysostomos and Sirakoulis, Georgios Ch. and Dimitrakopoulos, Giorgos},
  booktitle={{IEEE} Intern. Symp. on Circuits and Systems ({ISCAS})}, 
  title={{RISC-V$^2$: A Scalable RISC-V Vector Processor}}, 
  pages={1--5},
  year={2020},
  }
  
@ARTICLE {ara,
author = {M. Cavalcante and F. Schuiki and F. Zaruba and M. Schaffner and L. Benini},
journal = {IEEE Trans. on VLSI Systems},
title = {{Ara: A 1-GHz+ Scalable and Energy-Efficient {RISC-V} Vector Processor With Multiprecision Floating-Point Support in 22-nm {FD-SOI}}},
year = {2020},
volume = {28},
number = {2},
pages = {530-543}
}








@book{fingeroff2010high,
  title={{High-level synthesis: blue book}},
  author={Fingeroff, Michael},
  year={2010},
  publisher={Xlibris Corporation}
}

@inproceedings{park20219,
  title={{A 6k-MAC feature-map-sparsity-aware neural processing unit in 5nm flagship mobile SoC}},
  author={Park, Jun-Seok and Jang, Jun-Woo and Lee, Heonsoo and Lee, Dongwoo and Lee, Sehwan and Jung, Hanwoong and Lee, Seungwon and Kwon, Suknam and Jeong, Kyungah and Song, Joon-Ho and others},
  booktitle={{IEEE} Intern. Solid-State Circ. Conf. (ISSCC)},
  pages={152--154},
  year={2021},
}

@inproceedings{song20197,
  title={{An 11.5 TOPS/W 1024-MAC butterfly structure dual-core sparsity-aware neural processing unit in 8nm flagship mobile SoC}},
  author={Song, Jinook and Cho, Yunkyo and Park, Jun-Seok and Jang, Jun-Woo and Lee, Sehwan and Song, Joon-Ho and Lee, Jae-Gon and Kang, Inyup},
  booktitle={{IEEE} Intern. Solid-State Circ. Conf. (ISSCC)},
  pages={130--132},
  year={2019},
}

@article{NIA-fp8,
  title={FP8 Formats for Deep Learning},
  author={Micikevicius, Paulius and Stosic, Dusan and Burgess, Neil and Cornea, Marius and Dubey, Pradeep and Grisenthwaite, Richard and Ha, Sangwon and Heinecke, Alexander and Judd, Patrick and Kamalu, John and others},
  journal={arXiv preprint arXiv:2209.05433},
  year={2022}
}

@ARTICLE{lzc,
  author={Dimitrakopoulos, Giorgos and Galanopoulos, Kostas and Mavrokefalidis, Christos and Nikolos, Dimitris},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={Low-Power Leading-Zero Counting and Anticipation Logic for High-Speed Floating Point Units}, 
  year={2008},
  volume={16},
  number={7},
  pages={837-850},}
 

@INPROCEEDINGS{lza,
  author={Schmookler, M.S. and Nowka, K.J.},
  booktitle={IEEE Symp. on Computer Arithmetic (ARITH)}, 
  title={Leading zero anticipation and detection-a comparison of methods}, 
  year={2001},
  pages={7-12},}

  @inproceedings{dlfloat,
title={{
DLFloat: A 16-b Floating Point format
designed for
Deep Learning Training and Inference}},
author={Agrawal, Ankur and Mueller, Silvia M. and Fleischer, Bruce M. and Sun, Xiao and Wang, Naigang and Choi, Jungwook and Gopalakrishnan, Kailash},
booktitle={Int. Symp. on Computer Arithmetic (ARITH)},
year={2019}}

  @INPROCEEDINGS{galal-fma,  
    author={Galal, Sameh and Horowitz, Mark},  
    booktitle={IEEE Symp. on Comp. Arithmetic (ARITH)},   
    title={Latency Sensitive FMA Design},   
    year={2011},  
    pages={129-138},}

@ARTICLE{bruguera-fma-align-first,
  author={Lang, T. and Bruguera, J.D.},
  journal={IEEE Transactions on Computers}, 
  title={Floating-point multiply-add-fused with reduced latency}, 
  year={2004},
  volume={53},
  number={8},
  pages={988-1003},
}

@INPROCEEDINGS{mocast-lp-sa,
  author={Peltekis, Christodoulos and Filippas, Dionysios and Dimitrakopoulos, Giorgos and Nicopoulos, Chrysostomos},
  booktitle={Intern. Conf. on Modern Circuits and Systems Technologies (MOCAST)}, 
  title={Low-Power Data Streaming in Systolic Arrays with Bus-Invert Coding and Zero-Value Clock Gating}, 
  year={2023},}



@article{attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@ARTICLE{multiprecision-align-first,
  author={Zhang, Hao and Chen, Dongdong and Ko, Seok-Bum},
  journal={IEEE Transactions on Computers}, 
  title={Efficient Multiple-Precision Floating-Point Fused Multiply-Add with Mixed-Precision Support}, 
  year={2019},
  volume={68},
  number={7},
  pages={1035-1048},
}

@inproceedings{aicas,
author={Filippas, Dionysios  and Peltekis, Christodoulos and
  Dimitrakopoulos, Giorgos and Nicopoulos, Chrysostomos},
booktitle={IEEE Intern. Conference on Artificial Intelligence Circuits and Systems (AICAS)},
title={{Reduced-Precision Floating-Point Arithmetic in Systolic Arrays with Skewed Pipelines}},
year={2023}}

@Article{fast-float,
AUTHOR = {Filippas, Dionysios and Nicopoulos, Chrysostomos and Dimitrakopoulos, Giorgos},
TITLE = {Templatized Fused Vector Floating-Point Dot Product for High-Level Synthesis},
JOURNAL = {Journal of Low Power Electronics and Applications},
VOLUME = {12},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {56},
}