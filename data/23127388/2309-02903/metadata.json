{
  "title": "Towards Efficient Training with Negative Samples in Visual Tracking",
  "authors": [
    "Qingmao Wei",
    "Bi Zeng",
    "Guotian Zeng"
  ],
  "submission_date": "2023-09-06T10:52:57+00:00",
  "revised_dates": [
    "2023-09-06T10:52:57+00:00"
  ],
  "publication_venue": null,
  "abstract": "Current state-of-the-art (SOTA) methods in visual object tracking often\nrequire extensive computational resources and vast amounts of training data,\nleading to a risk of overfitting. This study introduces a more efficient\ntraining strategy to mitigate overfitting and reduce computational\nrequirements. We balance the training process with a mix of negative and\npositive samples from the outset, named as Joint learning with Negative samples\n(JN). Negative samples refer to scenarios where the object from the template is\nnot present in the search region, which helps to prevent the model from simply\nmemorizing the target, and instead encourages it to use the template for object\nlocation. To handle the negative samples effectively, we adopt a\ndistribution-based head, which modeling the bounding box as distribution of\ndistances to express uncertainty about the target's location in the presence of\nnegative samples, offering an efficient way to manage the mixed sample\ntraining. Furthermore, our approach introduces a target-indicating token. It\nencapsulates the target's precise location within the template image. This\nmethod provides exact boundary details with negligible computational cost but\nimproving performance. Our model, JN-256, exhibits superior performance on\nchallenging benchmarks, achieving 75.8% AO on GOT-10k and 84.1% AUC on\nTrackingNet. Notably, JN-256 outperforms previous SOTA trackers that utilize\nlarger models and higher input resolutions, even though it is trained with only\nhalf the number of data sampled used in those works.",
  "categories": [
    "cs.CV"
  ],
  "arxiv_id": "2309.02903"
}