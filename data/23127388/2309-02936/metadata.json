{
  "title": "EdgeFL: A Lightweight Decentralized Federated Learning Framework",
  "authors": [
    "Hongyi Zhang",
    "Jan Bosch",
    "Helena Holmstr√∂m Olsson"
  ],
  "submission_date": "2023-09-06T11:55:41+00:00",
  "revised_dates": [
    "2023-09-06T11:55:41+00:00"
  ],
  "publication_venue": null,
  "abstract": "Federated Learning (FL) has emerged as a promising approach for collaborative\nmachine learning, addressing data privacy concerns. However, existing FL\nplatforms and frameworks often present challenges for software engineers in\nterms of complexity, limited customization options, and scalability\nlimitations. In this paper, we introduce EdgeFL, an edge-only lightweight\ndecentralized FL framework, designed to overcome the limitations of centralized\naggregation and scalability in FL deployments. By adopting an edge-only model\ntraining and aggregation approach, EdgeFL eliminates the need for a central\nserver, enabling seamless scalability across diverse use cases. With a\nstraightforward integration process requiring just four lines of code (LOC),\nsoftware engineers can easily incorporate FL functionalities into their AI\nproducts. Furthermore, EdgeFL offers the flexibility to customize aggregation\nfunctions, empowering engineers to adapt them to specific needs. Based on the\nresults, we demonstrate that EdgeFL achieves superior performance compared to\nexisting FL platforms/frameworks. Our results show that EdgeFL reduces weights\nupdate latency and enables faster model evolution, enhancing the efficiency of\nedge devices. Moreover, EdgeFL exhibits improved classification accuracy\ncompared to traditional centralized FL approaches. By leveraging EdgeFL,\nsoftware engineers can harness the benefits of federated learning while\novercoming the challenges associated with existing FL platforms/frameworks.",
  "categories": [
    "cs.SE",
    "cs.AI"
  ],
  "arxiv_id": "2309.02936"
}