{
  "title": "Vote2Cap-DETR++: Decoupling Localization and Describing for End-to-End 3D Dense Captioning",
  "authors": [
    "Sijin Chen",
    "Hongyuan Zhu",
    "Mingsheng Li",
    "Xin Chen",
    "Peng Guo",
    "Yinjie Lei",
    "Gang Yu",
    "Taihao Li",
    "Tao Chen"
  ],
  "submission_date": "2023-09-06T13:43:27+00:00",
  "revised_dates": [
    "2023-09-06T13:43:27+00:00"
  ],
  "publication_venue": null,
  "abstract": "3D dense captioning requires a model to translate its understanding of an\ninput 3D scene into several captions associated with different object regions.\nExisting methods adopt a sophisticated \"detect-then-describe\" pipeline, which\nbuilds explicit relation modules upon a 3D detector with numerous hand-crafted\ncomponents. While these methods have achieved initial success, the cascade\npipeline tends to accumulate errors because of duplicated and inaccurate box\nestimations and messy 3D scenes. In this paper, we first propose Vote2Cap-DETR,\na simple-yet-effective transformer framework that decouples the decoding\nprocess of caption generation and object localization through parallel\ndecoding. Moreover, we argue that object localization and description\ngeneration require different levels of scene understanding, which could be\nchallenging for a shared set of queries to capture. To this end, we propose an\nadvanced version, Vote2Cap-DETR++, which decouples the queries into\nlocalization and caption queries to capture task-specific features.\nAdditionally, we introduce the iterative spatial refinement strategy to vote\nqueries for faster convergence and better localization performance. We also\ninsert additional spatial information to the caption head for more accurate\ndescriptions. Without bells and whistles, extensive experiments on two commonly\nused datasets, ScanRefer and Nr3D, demonstrate Vote2Cap-DETR and\nVote2Cap-DETR++ surpass conventional \"detect-then-describe\" methods by a large\nmargin. Codes will be made available at\nhttps://github.com/ch3cook-fdu/Vote2Cap-DETR.",
  "categories": [
    "cs.CV"
  ],
  "arxiv_id": "2309.02999"
}