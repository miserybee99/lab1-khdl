\begin{table}[htbp]
    \centering
    \caption{
    \textbf{Set to Set training and performance on the ScanRefer validation set.} 
    %
    We compare our proposed set-to-set training with traditional ``Sentence Training'', which traverses through all sentence annotations.
    %
    We achieve comparable performance with MLE training, and 2.38\% C@0.5 improvement with SCST.
    }
    \label{tab:set-to-set-training}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{cccccc}
    \toprule
    Training                 & $\mathcal{L}_{des}$   & C@0.5$\uparrow$ & B-4@0.5$\uparrow$ & M@0.5$\uparrow$ & R@0.5$\uparrow$ \\ \hline
    Sentence                 & \multirow{2}{*}{MLE}  & 61.21           & \textbf{35.35}    & 26.12           & \textbf{54.52}  \\
    Set-to-Set               &                       & \textbf{61.81}  & 34.46             & \textbf{26.22}  & 54.40           \\ \hline
    Sentence                 & \multirow{2}{*}{SCST} & 71.39           & 37.57             & 26.01           & 54.28           \\
    Set-to-Set               &                       & \textbf{73.77}  & \textbf{38.21}           & \textbf{26.64}        & \textbf{54.71}  \\ \bottomrule
    \end{tabular}
    }
\end{table}


\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{exp-fig/caption_curve.pdf}
	\caption{
	\textbf{Set-to-Set training and model convergence on the ScanRefer validation set.} 
	%
	We analyze the convergence of two different training strategies with MLE training and SCST.
	%
	Set-to-Set training enables a larger batch size for captioning and accelerates convergence.
	}
	\label{fig:set-to-set}
\end{figure}