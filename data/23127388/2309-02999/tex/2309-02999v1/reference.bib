@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% marker-based and marker-less mocap

@inproceedings{chen2021scan2cap,
  title={Scan2cap: Context-aware dense captioning in rgb-d scans},
  author={Chen, Zhenyu and Gholami, Ali and Nie{\ss}ner, Matthias and Chang, Angel X},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3193--3203},
  year={2021}
}

@inproceedings{yuan2022x-trans2cap,
  title={X-trans2cap: Cross-modal knowledge transfer using transformer for 3d dense captioning},
  author={Yuan, Zhihao and Yan, Xu and Liao, Yinghong and Guo, Yao and Li, Guanbin and Cui, Shuguang and Li, Zhen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8563--8573},
  year={2022}
}

@article{wang2022spacap3d,
  title={Spatiality-guided Transformer for 3D Dense Captioning on Point Clouds},
  author={Wang, Heng and Zhang, Chaoyi and Yu, Jianhui and Cai, Weidong},
  journal={arXiv preprint arXiv:2204.10688},
  year={2022}
}

@article{jiao2022more,
  title={MORE: Multi-Order RElation Mining for Dense Captioning in 3D Scenes},
  author={Jiao, Yang and Chen, Shaoxiang and Jie, Zequn and Chen, Jingjing and Ma, Lin and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2203.05203},
  year={2022}
}

@article{chen2021d3net,
  title={D3Net: A Speaker-Listener Architecture for Semi-supervised Dense Captioning and Visual Grounding in RGB-D Scans},
  author={Chen, Dave Zhenyu and Wu, Qirui and Nie{\ss}ner, Matthias and Chang, Angel X},
  journal={arXiv preprint arXiv:2112.01551},
  year={2021}
}

@inproceedings{cai20223djcg,
  title={3DJCG: A Unified Framework for Joint Dense Captioning and Visual Grounding on 3D Point Clouds},
  author={Cai, Daigang and Zhao, Lichen and Zhang, Jing and Sheng, Lu and Xu, Dong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16464--16473},
  year={2022}
}

@inproceedings{qi2019votenet,
  title={Deep hough voting for 3d object detection in point clouds},
  author={Qi, Charles R and Litany, Or and He, Kaiming and Guibas, Leonidas J},
  booktitle={proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9277--9286},
  year={2019}
}

@inproceedings{jiang2020pointgroup,
  title={Pointgroup: Dual-set point grouping for 3d instance segmentation},
  author={Jiang, Li and Zhao, Hengshuang and Shi, Shaoshuai and Liu, Shu and Fu, Chi-Wing and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and Pattern recognition},
  pages={4867--4876},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{gilmer2017gnn,
  title={Neural message passing for quantum chemistry},
  author={Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
  booktitle={International conference on machine learning},
  pages={1263--1272},
  year={2017},
  organization={PMLR}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@article{radford2019gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{misra2021-3detr,
  title={An end-to-end transformer model for 3d object detection},
  author={Misra, Ishan and Girdhar, Rohit and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2906--2917},
  year={2021}
}

@inproceedings{dai2017scannet,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}

@inproceedings{chen2020scanrefer,
  title={Scanrefer: 3d object localization in rgb-d scans using natural language},
  author={Chen, Dave Zhenyu and Chang, Angel X and Nie{\ss}ner, Matthias},
  booktitle={European Conference on Computer Vision},
  pages={202--221},
  year={2020},
  organization={Springer}
}

@inproceedings{zhao20213dvg,
  title={3DVG-Transformer: Relation modeling for visual grounding on point clouds},
  author={Zhao, Lichen and Cai, Daigang and Sheng, Lu and Xu, Dong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2928--2937},
  year={2021}
}

@inproceedings{neubeck2006nms,
  title={Efficient non-maximum suppression},
  author={Neubeck, Alexander and Van Gool, Luc},
  booktitle={18th International Conference on Pattern Recognition (ICPR'06)},
  volume={3},
  pages={850--855},
  year={2006},
  organization={IEEE}
}

@inproceedings{achlioptas2020referit3d,
  title={Referit3d: Neural listeners for fine-grained 3d object identification in real-world scenes},
  author={Achlioptas, Panos and Abdelreheem, Ahmed and Xia, Fei and Elhoseiny, Mohamed and Guibas, Leonidas},
  booktitle={European Conference on Computer Vision},
  pages={422--440},
  year={2020},
  organization={Springer}
}

@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{carion2020detr,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@inproceedings{roh2022languagerefer,
  title={Languagerefer: Spatial-language model for 3d visual grounding},
  author={Roh, Junha and Desingh, Karthik and Farhadi, Ali and Fox, Dieter},
  booktitle={Conference on Robot Learning},
  pages={1046--1056},
  year={2022},
  organization={PMLR}
}

@inproceedings{huang2021tgnn,
  title={Text-guided graph neural networks for referring 3d instance segmentation},
  author={Huang, Pin-Hao and Lee, Han-Hung and Chen, Hwann-Tzong and Liu, Tyng-Luh},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={2},
  pages={1610--1618},
  year={2021}
}

@inproceedings{yang2021sat,
  title={Sat: 2d semantics assisted training for 3d visual grounding},
  author={Yang, Zhengyuan and Zhang, Songyang and Wang, Liwei and Luo, Jiebo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1856--1866},
  year={2021}
}

@inproceedings{feng2021ffl,
  title={Free-form description guided 3d visual graph network for object grounding in point cloud},
  author={Feng, Mingtao and Li, Zhen and Li, Qi and Zhang, Liang and Zhang, XiangDong and Zhu, Guangming and Zhang, Hui and Wang, Yaonan and Mian, Ajmal},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3722--3731},
  year={2021}
}

@inproceedings{he2021transrefer3d,
  title={TransRefer3D: Entity-and-Relation Aware Transformer for Fine-Grained 3D Visual Grounding},
  author={He, Dailan and Zhao, Yusheng and Luo, Junyu and Hui, Tianrui and Huang, Shaofei and Zhang, Aixi and Liu, Si},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={2344--2352},
  year={2021}
}

@inproceedings{yuan2021instancerefer,
  title={Instancerefer: Cooperative holistic understanding for visual grounding on point clouds through instance multi-level contextual referring},
  author={Yuan, Zhihao and Yan, Xu and Liao, Yinghong and Zhang, Ruimao and Wang, Sheng and Li, Zhen and Cui, Shuguang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1791--1800},
  year={2021}
}

@inproceedings{luo20223dsps,
  title={3D-SPS: Single-Stage 3D Visual Grounding via Referred Point Progressive Selection},
  author={Luo, Junyu and Fu, Jiahui and Kong, Xianghao and Gao, Chen and Ren, Haibing and Shen, Hao and Xia, Huaxia and Liu, Si},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16454--16463},
  year={2022}
}

@article{jain2021looking,
  title={Looking Outside the Box to Ground Language in 3D Scenes},
  author={Jain, Ayush and Gkanatsios, Nikolaos and Mediratta, Ishita and Fragkiadaki, Katerina},
  journal={arXiv preprint arXiv:2112.08879},
  year={2021}
}

@inproceedings{abdelreheem20223dreftransformer,
  title={3DRefTransformer: Fine-Grained Object Identification in Real-World Scenes Using Natural Language},
  author={Abdelreheem, Ahmed and Upadhyay, Ujjwal and Skorokhodov, Ivan and Al Yahya, Rawan and Chen, Jun and Elhoseiny, Mohamed},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3941--3950},
  year={2022}
}

@inproceedings{liu2021groupfree3d,
  title={Group-free 3d object detection via transformers},
  author={Liu, Ze and Zhang, Zheng and Cao, Yue and Hu, Han and Tong, Xin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2949--2958},
  year={2021}
}

@inproceedings{chen2020hgnet,
  title={A hierarchical graph network for 3d object detection on point clouds},
  author={Chen, Jintai and Lei, Biwen and Song, Qingyu and Ying, Haochao and Chen, Danny Z and Wu, Jian},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={392--401},
  year={2020}
}

@inproceedings{zhang2020h3dnet,
  title={H3dnet: 3d object detection using hybrid geometric primitives},
  author={Zhang, Zaiwei and Sun, Bo and Yang, Haitao and Huang, Qixing},
  booktitle={European Conference on Computer Vision},
  pages={311--329},
  year={2020},
  organization={Springer}
}

@article{chen2022pq,
  title={Pq-transformer: Jointly parsing 3d objects and layouts from point clouds},
  author={Chen, Xiaoxue and Zhao, Hao and Zhou, Guyue and Zhang, Ya-Qin},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={2},
  pages={2519--2526},
  year={2022},
  publisher={IEEE}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@inproceedings{rennie2017scst,
  title={Self-critical sequence training for image captioning},
  author={Rennie, Steven J and Marcheret, Etienne and Mroueh, Youssef and Ross, Jerret and Goel, Vaibhava},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7008--7024},
  year={2017}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@article{loshchilov2017AdamW,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{paszke2016enet,
  title={Enet: A deep neural network architecture for real-time semantic segmentation},
  author={Paszke, Adam and Chaurasia, Abhishek and Kim, Sangpil and Culurciello, Eugenio},
  journal={arXiv preprint arXiv:1606.02147},
  year={2016}
}

@inproceedings{anderson2018bottom-up-top-down,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@inproceedings{cornia2020m2transformer,
  title={Meshed-memory transformer for image captioning},
  author={Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10578--10587},
  year={2020}
}

@article{liu2021cptr,
  title={CPTR: Full transformer network for image captioning},
  author={Liu, Wei and Chen, Sihan and Guo, Longteng and Zhu, Xinxin and Liu, Jing},
  journal={arXiv preprint arXiv:2101.10804},
  year={2021}
}

@inproceedings{huang2019AinA-img-cap,
  title={Attention on attention for image captioning},
  author={Huang, Lun and Wang, Wenmin and Chen, Jie and Wei, Xiao-Yong},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4634--4643},
  year={2019}
}

@inproceedings{pan2020x-linear-img-cap,
  title={X-linear attention networks for image captioning},
  author={Pan, Yingwei and Yao, Ting and Li, Yehao and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10971--10980},
  year={2020}
}

@inproceedings{zhang2021rstnet,
  title={RSTNet: Captioning with adaptive attention on visual and non-visual words},
  author={Zhang, Xuying and Sun, Xiaoshuai and Luo, Yunpeng and Ji, Jiayi and Zhou, Yiyi and Wu, Yongjian and Huang, Feiyue and Ji, Rongrong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={15465--15474},
  year={2021}
}

@article{nguyen2022grit,
  title={GRIT: Faster and Better Image captioning Transformer Using Dual Visual Features},
  author={Nguyen, Van-Quang and Suganuma, Masanori and Okatani, Takayuki},
  journal={arXiv preprint arXiv:2207.09666},
  year={2022}
}

@inproceedings{tian2019fcos,
  title={Fcos: Fully convolutional one-stage object detection},
  author={Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9627--9636},
  year={2019}
}

@article{tancik2020fourier,
  title={Fourier features let networks learn high frequency functions in low dimensional domains},
  author={Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7537--7547},
  year={2020}
}

@article{chen2022conditionaldetrv2,
  title={Conditional detr v2: Efficient detection transformer with box queries},
  author={Chen, Xiaokang and Wei, Fangyun and Zeng, Gang and Wang, Jingdong},
  journal={arXiv preprint arXiv:2207.08914},
  year={2022}
}

@misc{zhang2022dino,
      title={DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection}, 
      author={Hao Zhang and Feng Li and Shilong Liu and Lei Zhang and Hang Su and Jun Zhu and Lionel M. Ni and Heung-Yeung Shum},
      year={2022},
      eprint={2203.03605},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{zhong2022contextual3DdenseCap,
  title={Contextual Modeling for 3D Dense Captioning on Point Clouds},
  author={Zhong, Yufeng and Xu, Long and Luo, Jiebo and Ma, Lin},
  journal={arXiv preprint arXiv:2210.03925},
  year={2022}
}

@inproceedings{meng2021conditionaldetr,
  title={Conditional detr for fast training convergence},
  author={Meng, Depu and Chen, Xiaokang and Fan, Zejia and Zeng, Gang and Li, Houqiang and Yuan, Yuhui and Sun, Lei and Wang, Jingdong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3651--3660},
  year={2021}
}

@article{zhu2020deformabledetr,
  title={Deformable detr: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  journal={arXiv preprint arXiv:2010.04159},
  year={2020}
}

@inproceedings{zhang2021depthcontrast,
  title={Self-supervised pretraining of 3d features on any point-cloud},
  author={Zhang, Zaiwei and Girdhar, Rohit and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10252--10263},
  year={2021}
}

@article{zhang2022detr++,
  title={DETR++: Taming Your Multi-Scale Detection Transformer},
  author={Zhang, Chi and Liu, Lijuan and Zang, Xiaoxue and Liu, Frederick and Zhang, Hao and Song, Xinying and Chen, Jindong},
  journal={arXiv preprint arXiv:2206.02977},
  year={2022}
}

@inproceedings{gao2021fast,
  title={Fast convergence of detr with spatially modulated co-attention},
  author={Gao, Peng and Zheng, Minghang and Wang, Xiaogang and Dai, Jifeng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3621--3630},
  year={2021}
}

@article{chen2022groupdetr,
  title={Group DETR: Fast Training Convergence with Decoupled One-to-Many Label Assignment},
  author={Chen, Qiang and Chen, Xiaokang and Zeng, Gang and Wang, Jingdong},
  journal={arXiv preprint arXiv:2207.13085},
  year={2022}
}

@article{jia2022hybriddetrs,
  title={DETRs with Hybrid Matching},
  author={Jia, Ding and Yuan, Yuhui and He, Haodi and Wu, Xiaopei and Yu, Haojun and Lin, Weihong and Sun, Lei and Zhang, Chao and Hu, Han},
  journal={arXiv preprint arXiv:2207.13080},
  year={2022}
}

@inproceedings{wang2022detr3d,
  title={Detr3d: 3d object detection from multi-view images via 3d-to-2d queries},
  author={Wang, Yue and Guizilini, Vitor Campagnolo and Zhang, Tianyuan and Wang, Yilun and Zhao, Hang and Solomon, Justin},
  booktitle={Conference on Robot Learning},
  pages={180--191},
  year={2022},
  organization={PMLR}
}

@inproceedings{wang2021pdvc,
  title={End-to-end dense video captioning with parallel decoding},
  author={Wang, Teng and Zhang, Ruimao and Lu, Zhichao and Zheng, Feng and Cheng, Ran and Luo, Ping},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6847--6857},
  year={2021}
}

@inproceedings{zhou2018end,
  title={End-to-end dense video captioning with masked transformer},
  author={Zhou, Luowei and Zhou, Yingbo and Corso, Jason J and Socher, Richard and Xiong, Caiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8739--8748},
  year={2018}
}


@inproceedings{wang2022anchor,
  title={Anchor detr: Query design for transformer-based detector},
  author={Wang, Yingming and Zhang, Xiangyu and Yang, Tong and Sun, Jian},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  number={3},
  pages={2567--2575},
  year={2022}
}


@inproceedings{liu2022maskpoint,
  title={Masked discrimination for self-supervised learning on point clouds},
  author={Liu, Haotian and Cai, Mu and Lee, Yong Jae},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part II},
  pages={657--675},
  year={2022},
  organization={Springer}
}

@inproceedings{ye2022makes,
  title={What Makes for Effective Few-shot Point Cloud Classification?},
  author={Ye, Chuangguan and Zhu, Hongyuan and Liao, Yongbin and Zhang, Yanggang and Chen, Tao and Fan, Jiayuan},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={1829--1838},
  year={2022}
}

@article{liao2021point,
  title={Point cloud instance segmentation with semi-supervised bounding-box mining},
  author={Liao, Yongbin and Zhu, Hongyuan and Zhang, Yanggang and Ye, Chuangguan and Chen, Tao and Fan, Jiayuan},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={12},
  pages={10159--10170},
  year={2021},
  publisher={IEEE}
}

@article{chen2021sportscap,
  title={Sportscap: Monocular 3d human motion capture and fine-grained understanding in challenging sports videos},
  author={Chen, Xin and Pang, Anqi and Yang, Wei and Ma, Yuexin and Xu, Lan and Yu, Jingyi},
  journal={International Journal of Computer Vision},
  volume={129},
  pages={2846--2864},
  year={2021},
  publisher={Springer}
}

@article{chen2021tightcap,
  title={Tightcap: 3D human shape capture with clothing tightness field},
  author={Chen, Xin and Pang, Anqi and Yang, Wei and Wang, Peihao and Xu, Lan and Yu, Jingyi},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={1},
  pages={1--17},
  year={2021},
  publisher={ACM New York, NY}
}

@article{yin2023dcnet,
  title={DCNet: Large-scale Point Cloud Semantic Segmentation with Discriminative and Efficient Feature Aggregation},
  author={Yin, Fukun and Huang, Zilong and Chen, Tao and Luo, Guozhong and Yu, Gang and Fu, Bin},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2023},
  publisher={IEEE}
}


@inproceedings{jin2023context,
  title={Context-aware Alignment and Mutual Masking for 3D-Language Pre-training},
  author={Jin, Zhao and Hayat, Munawar and Yang, Yuwei and Guo, Yulan and Lei, Yinjie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10984--10994},
  year={2023}
}


@inproceedings{chen2023vote2cap,
  title={End-to-end 3d dense captioning with vote2cap-detr},
  author={Chen, Sijin and Zhu, Hongyuan and Chen, Xin and Lei, Yinjie and Yu, Gang and Chen, Tao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11124--11133},
  year={2023}
}


@article{chen2022unit3d,
  title={UniT3D: A Unified Transformer for 3D Dense Captioning and Visual Grounding},
  author={Chen, Dave Zhenyu and Hu, Ronghang and Chen, Xinlei and Nie{\ss}ner, Matthias and Chang, Angel X},
  journal={arXiv preprint arXiv:2212.00836},
  year={2022}
}


@inproceedings{hayashi2022recurrent,
  title={A Recurrent Point Clouds Selection Method for 3D Dense Captioning},
  author={Hayashi, Shinko and Zhang, Zhiqiang and Zhou, Jinja},
  booktitle={International Conference on Neural Information Processing},
  pages={263--274},
  year={2022},
  organization={Springer}
}

@article{mao2023complete,
  title={Complete 3D Relationships Extraction Modality Alignment Network for 3D Dense Captioning},
  author={Mao, Aihua and Yang, Zhi and Chen, Wanxin and Yi, Ran and Liu, Yong-jin},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2023},
  publisher={IEEE}
}


@inproceedings{azuma2022scanqa,
  title={ScanQA: 3D question answering for spatial scene understanding},
  author={Azuma, Daichi and Miyanishi, Taiki and Kurita, Shuhei and Kawanabe, Motoaki},
  booktitle={proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={19129--19139},
  year={2022}
}

@article{ye20223dqa,
  title={3D question answering},
  author={Ye, Shuquan and Chen, Dongdong and Han, Songfang and Liao, Jing},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2022},
  publisher={IEEE}
}

@article{wang2019edgeconv,
  title={Dynamic graph cnn for learning on point clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E and Bronstein, Michael M and Solomon, Justin M},
  journal={ACM Transactions on Graphics (tog)},
  volume={38},
  number={5},
  pages={1--12},
  year={2019},
  publisher={ACM New York, NY, USA}
}


@inproceedings{wu2023eda,
  title={EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual Grounding},
  author={Wu, Yanmin and Cheng, Xinhua and Zhang, Renrui and Cheng, Zesen and Zhang, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19231--19242},
  year={2023}
}

@article{ma2022sqa3d,
  title={Sqa3d: Situated question answering in 3d scenes},
  author={Ma, Xiaojian and Yong, Silong and Zheng, Zilong and Li, Qing and Liang, Yitao and Zhu, Song-Chun and Huang, Siyuan},
  journal={arXiv preprint arXiv:2210.07474},
  year={2022}
}

@inproceedings{li2023litedetr,
  title={Lite DETR: An interleaved multi-scale encoder for efficient detr},
  author={Li, Feng and Zeng, Ailing and Liu, Shilong and Zhang, Hao and Li, Hongyang and Zhang, Lei and Ni, Lionel M},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18558--18567},
  year={2023}
}

@article{liu2023stabledetr,
  title={Detection Transformer with Stable Matching},
  author={Liu, Shilong and Ren, Tianhe and Chen, Jiayu and Zeng, Zhaoyang and Zhang, Hao and Li, Feng and Li, Hongyang and Huang, Jun and Su, Hang and Zhu, Jun and others},
  journal={arXiv preprint arXiv:2304.04742},
  year={2023}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}


@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{cornia2020meshed,
  title={Meshed-memory transformer for image captioning},
  author={Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10578--10587},
  year={2020}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}


@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}


@article{zhu2022exploring,
  title={Exploring discrete diffusion models for image captioning},
  author={Zhu, Zixin and Wei, Yixuan and Wang, Jianfeng and Gan, Zhe and Zhang, Zheng and Wang, Le and Hua, Gang and Wang, Lijuan and Liu, Zicheng and Hu, Han},
  journal={arXiv preprint arXiv:2211.11694},
  year={2022}
}


@inproceedings{luo2023semantic,
  title={Semantic-conditional diffusion networks for image captioning},
  author={Luo, Jianjie and Li, Yehao and Pan, Yingwei and Yao, Ting and Feng, Jianlin and Chao, Hongyang and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23359--23368},
  year={2023}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}


@inproceedings{wang2021end,
  title={End-to-end dense video captioning with parallel decoding},
  author={Wang, Teng and Zhang, Ruimao and Lu, Zhichao and Zheng, Feng and Cheng, Ran and Luo, Ping},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6847--6857},
  year={2021}
}

@inproceedings{krishna2017dense,
  title={Dense-captioning events in videos},
  author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={706--715},
  year={2017}
}


@article{yu2023survey,
  title={A Comprehensive Survey of 3D Dense Captioning: Localizing and Describing Objects in 3D Scenes},
  author={Yu, Ting and Lin, Xiaojun and Wang, Shuhui and Sheng, Weiguo and Huang, Qingming and Yu, Jun},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2023},
  publisher={IEEE}
}


@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}


@article{brown2020gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{he2016resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{ba2016layernorm,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}



@inproceedings{chen2023executing,
  title={Executing your Commands via Motion Diffusion in Latent Space},
  author={Chen, Xin and Jiang, Biao and Liu, Wen and Huang, Zilong and Fu, Bin and Chen, Tao and Yu, Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18000--18010},
  year={2023}
}

@article{lu2023large,
  title={A Large-Scale Outdoor Multi-modal Dataset and Benchmark for Novel View Synthesis and Implicit Scene Reconstruction},
  author={Lu, Chongshan and Yin, Fukun and Chen, Xin and Chen, Tao and Yu, Gang and Fan, Jiayuan},
  journal={arXiv preprint arXiv:2301.06782},
  year={2023}
}

@article{yin2022coordinates,
  title={Coordinates Are NOT Lonely-Codebook Prior Helps Implicit Neural 3D Representations},
  author={Yin, Fukun and Liu, Wen and Huang, Zilong and Cheng, Pei and Chen, Tao and Yu, Gang},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12705--12717},
  year={2022}
}

@article{zhao2021transformer3d,
  title={Transformer3D-Det: Improving 3D object detection by vote refinement},
  author={Zhao, Lichen and Guo, Jinyang and Xu, Dong and Sheng, Lu},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={31},
  number={12},
  pages={4735--4746},
  year={2021},
  publisher={IEEE}
}


@article{guo2020deep,
  title={Deep learning for 3d point clouds: A survey},
  author={Guo, Yulan and Wang, Hanyun and Hu, Qingyong and Liu, Hao and Liu, Li and Bennamoun, Mohammed},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={12},
  pages={4338--4364},
  year={2020},
  publisher={IEEE}
}

@article{lin2021learning,
  title={Learning of 3d graph convolution networks for point cloud analysis},
  author={Lin, Zhi-Hao and Huang, Sheng-Yu and Wang, Yu-Chiang Frank},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={8},
  pages={4212--4224},
  year={2021},
  publisher={IEEE}
}

@article{xiao2023unsupervised,
  title={Unsupervised point cloud representation learning with deep neural networks: A survey},
  author={Xiao, Aoran and Huang, Jiaxing and Guan, Dayan and Zhang, Xiaoqin and Lu, Shijian and Shao, Ling},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@article{hu2021learning,
  title={Learning semantic segmentation of large-scale point clouds with random sampling},
  author={Hu, Qingyong and Yang, Bo and Xie, Linhai and Rosa, Stefano and Guo, Yulan and Wang, Zhihua and Trigoni, Niki and Markham, Andrew},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={11},
  pages={8338--8354},
  year={2021},
  publisher={IEEE}
}

@article{meng2021towards,
  title={Towards a weakly supervised framework for 3d point cloud object detection and annotation},
  author={Meng, Qinghao and Wang, Wenguan and Zhou, Tianfei and Shen, Jianbing and Jia, Yunde and Van Gool, Luc},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={8},
  pages={4454--4468},
  year={2021},
  publisher={IEEE}
}