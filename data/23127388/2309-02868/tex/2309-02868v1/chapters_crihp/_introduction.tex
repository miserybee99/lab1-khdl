%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:intro}
Asynchronous time series, also named temporal event sequence data in some literature,  is ubiquitous in daily life, containing discrete events with varying marks and irregular inter-event time intervals. In this work, we focus on the task of event sequence forecasting, which leverages historical sequences to uncover interactions between successive events and predict future events' marks and arrival times. Recently, neural TPPs \cite{12:conf/nips/MeiE17, 50:conf/nips/XueSZM22} begin to show advantages in modeling event sequence, but existing methods mainly focus on parametrizing the conditional distribution of the next event \cite{17:conf/ijcai/ShchurTJG21, 49:journals/corr/abs-2307-08097}, and do not fully discuss how to model the relational structure between events. RNN-based TPPs \cite{11:conf/kdd/DuDTUGS16, 12:conf/nips/MeiE17, 13:journals/tnn/XiaoYFSYZ19} achieve significant progress in event forecasting task, but related methods ignore the explicit modeling of the relationship between events, which is difficult to help us intuitively understand the interactions between events. The Attention-based TPPs \cite{14:zhang2020self, 15:conf/icml/ZuoJLZZ20} use the matching function to construct the similarity coefficient between events, which is not a direct description of the interactions between events. Recently, some work has begun to focus on the relational Inference between events, methods based on Causal Inference \cite{18:conf/icml/XuFZ16, 19:conf/icml/AchabBGMM17, 20:eichler2017graphical,chu2023causal,chu2020matching} define the interaction between events by establishing granger causality, but such models usually make strong assumptions and are difficult to learn different types of influence relationships. Methods based on Graph Neural Networks (GNN) \cite{21:wu2020modeling, 22:conf/aaai/ShangS19, 23:conf/ijcnn/XueSHMZWW21, 24:conf/kdd/LiLKP21} typically construct static graphs according to the mark information. However, in real-world systems, the interactions between events evolve dynamically over time. Existing GNN-based methods struggle to model such dynamic changes in relationships. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Figure
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{images_crihp/fig-1}\par\caption{In the asynchronous time series forecasting model, different types of neural temporal point processes (including RNN-based model, Attention-based model and our proposed model) model the correlation between events in the historical sequence .}
\label{fig:fig-1}
\end{figure}

To address the problems above, we propose the Contrastive Relational Inference-based Hawkes Process (CRIHP), utilizing Neural Relational Inference to dynamically model the mutual interactions between events. We formulate the relational inference as a latent variable model, which is learned by variational inference. The latent variables describe the type and strength of interactions between the events \cite{chu2021graph}. Due to the flexibility of latent variable models, a relation graph can be generated as a multi-view graph, which can represent different kinds of interactions, and the generation process is dynamic. To ensure the reliability of the inferred relation graph, we design Contrastive Relational Inference architecture(CRI), which constructs contrasting relationship constraints in the latent space, ensuring that event sequences with similar dynamic patterns also possess similar relation structures \cite{chu2023leveraging,wang2023enhancing}. Furthermore, to accurately identify intent signals during sampling for CRI, we employ intensity-based learning to recognize prototypical paths, which represent the dynamic patterns of event sequence. Our method builds a bridge between the fields of TPP and NRI. A comparison of our proposed model with existing models is shown in Figure~\ref{fig:fig-1}. Extensive experiments on three real-world datasets demonstrate the effectiveness of our proposed model.