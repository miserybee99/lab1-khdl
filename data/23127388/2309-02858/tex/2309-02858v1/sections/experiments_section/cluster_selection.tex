\input{figs_tex/mnist/fig_number_clusters}

We repeat our previous experiment on the MNIST dataset from Sec.~\ref{ssec:exp_mnist}. We choose this time to get 50 clusters at best for both the MI and the MMD GEMINI and train the models for 100 epochs. We repeat the experiment 20 times per model and plot the resulting scores in figures~\ref{sfig:mlp_clusters} and~\ref{sfig:lenet_clusters}. We did not choose to test with the Wasserstein GEMINI because its complexity implies a long training time for 50 clusters, as explained in App.~\ref{app:exp_complexity}. We first observe in Fig.~\ref{fig:mnist_clusters} that the MMD-GEMINI with linear kernel has a tendency to exploit more clusters than the MI. The model converges to approximately 30 clusters in the case of the MLP and 25 for the LeNet-5 model with less variance. We can further observe that for all metrics the choice of architecture impacted the number of non-empty clusters after training. Indeed, by playing a key role in the decision boundary shape, the architecture may limit the number of clusters to be found: the MLP can draw more complex boundaries compared to the LeNet5 model. Moreover, we suppose that the cluster selection behaviour of GEMINI may be due to optimisation processes. Indeed, we optimise estimators of the GEMINI rather than the exact GEMINI.
Finally, Fig.~\ref{fig:mnist_clusters} also confirms from Table.~\ref{tab:mnist_experiment} the stability of the MMD-GEMINI regarding the ARI despite the change of architecture whereas the MI is affected and shows poor performance with the LeNet-5 architecture.